<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="HA概述1）所谓HA（High Available），即高可用（7*24小时不中断服务）。 2）实现高可用最关键的策略是消除单点故障。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。 3）Hadoop2.0之前，在HDFS集群中NameNode存在单点故障（SPOF）。 4）NameNode主要在以下两个方面影响HDFS集群">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop之HA高可用">
<meta property="og:url" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/index.html">
<meta property="og:site_name" content="没有尾巴的小驴">
<meta property="og:description" content="HA概述1）所谓HA（High Available），即高可用（7*24小时不中断服务）。 2）实现高可用最关键的策略是消除单点故障。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。 3）Hadoop2.0之前，在HDFS集群中NameNode存在单点故障（SPOF）。 4）NameNode主要在以下两个方面影响HDFS集群">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812101937092.png">
<meta property="og:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812120144955.png">
<meta property="og:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812102335986.png">
<meta property="og:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812103242485.png">
<meta property="og:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812104041183.png">
<meta property="og:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812112950810.png">
<meta property="article:published_time" content="2022-08-11T09:48:12.000Z">
<meta property="article:modified_time" content="2025-06-25T08:08:45.483Z">
<meta property="article:author" content="Rui Zhang">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812101937092.png">

<link rel="canonical" href="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>Hadoop之HA高可用 | 没有尾巴的小驴</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">没有尾巴的小驴</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">记录生活</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">22</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">22</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">52</span></a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.jpg">
      <meta itemprop="name" content="Rui Zhang">
      <meta itemprop="description" content="不在沉默中爆发，就在沉默中灭亡">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="没有尾巴的小驴">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop之HA高可用
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-08-11 17:48:12" itemprop="dateCreated datePublished" datetime="2022-08-11T17:48:12+08:00">2022-08-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-25 16:08:45" itemprop="dateModified" datetime="2025-06-25T16:08:45+08:00">2025-06-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>18k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>17 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="HA概述"><a href="#HA概述" class="headerlink" title="HA概述"></a>HA概述</h1><p>1）所谓HA（High Available），即高可用（7*24小时不中断服务）。</p>
<p>2）实现高可用最关键的策略是消除单点故障。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。</p>
<p>3）Hadoop2.0之前，在HDFS集群中NameNode存在单点故障（SPOF）。</p>
<p>4）NameNode主要在以下两个方面影响HDFS集群</p>
<p>​    NameNode机器发生意外，如宕机，集群将无法使用，直到管理员重启</p>
<p>​    NameNode机器需要升级，包括软件、硬件升级，此时集群也将无法使用</p>
<p>HDFS HA功能通过配置Active/Standby两个NameNodes实现在集群中对NameNode的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可通过此种方式将NameNode很快的切换到另外一台机器。</p>
<h1 id="HDFS-HA-集群搭建"><a href="#HDFS-HA-集群搭建" class="headerlink" title="HDFS-HA 集群搭建"></a>HDFS-HA 集群搭建</h1><p>当前 HDFS 集群的规划</p>
<table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td></td>
<td>Secondarynamenode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
</tbody></table>
<p>HA 的主要目的是消除 namenode 的单点故障,需要将 hdfs 集群规划成以下模样</p>
<table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
</tbody></table>
<h2 id="HDFS-HA-核心问题"><a href="#HDFS-HA-核心问题" class="headerlink" title="HDFS-HA 核心问题"></a>HDFS-HA 核心问题</h2><ol>
<li><p><strong>怎么保证三台 namenode 的数据一致</strong><br>a.Fsimage:让一台 nn 生成数据,让其他机器 nn 同步<br>b.Edits:需要引进新的模块 JournalNode 来保证 edtis 的文件的数据一致性</p>
</li>
<li><p><strong>怎么让同时只有一台 nn 是 active，其他所有是 standby 的</strong><br>a.手动分配<br>b.自动分配</p>
</li>
<li><p><strong>2nn 在 ha 架构中并不存在，定期合并 fsimage 和 edtis 的活谁来干</strong><br>由 standby 的 nn 来干</p>
</li>
<li><p><strong>如果 nn 真的发生了问题，怎么让其他的 nn 上位干活</strong><br>a.手动故障转移<br>b.自动故障转移  </p>
</li>
</ol>
<h1 id="HDFS-HA-手动模式"><a href="#HDFS-HA-手动模式" class="headerlink" title="HDFS-HA 手动模式"></a>HDFS-HA 手动模式</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>（1）修改 IP<br>（2）修改主机名及主机名和 IP 地址的映射<br>（3）关闭防火墙<br>（4） ssh 免密登录<br>（5）安装 JDK，配置环境变量等  </p>
<h2 id="规划集群"><a href="#规划集群" class="headerlink" title="规划集群"></a>规划集群</h2><table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
</tbody></table>
<h2 id="配置-Zookeeper-集群"><a href="#配置-Zookeeper-集群" class="headerlink" title="配置 Zookeeper 集群"></a>配置 Zookeeper 集群</h2><ol>
<li><p><strong>集群规划</strong></p>
<p>在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper。</p>
</li>
<li><p><strong>解压安装</strong></p>
<p>（1）解压Zookeeper安装包到/opt/module/目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf zookeeper-3.4.10.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>（2）在/opt/module/zookeeper-3.4.10/这个目录下创建zkData</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p zkData</span><br></pre></td></tr></table></figure>

<p>（3）重命名/opt/module/zookeeper-3.4.10/conf这个目录下的zoo_sample.cfg为zoo.cfg</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>配置zoo.cfg文件</strong></p>
<p>（1）具体配置</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataDir</span>=<span class="string">/opt/module/zookeeper-3.4.10/zkData</span></span><br></pre></td></tr></table></figure>

<p>增加如下配置</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#######################cluster##########################</span></span><br><span class="line"><span class="meta">server.2</span>=<span class="string">hadoop102:2888:3888</span></span><br><span class="line"><span class="meta">server.3</span>=<span class="string">hadoop103:2888:3888</span></span><br><span class="line"><span class="meta">server.4</span>=<span class="string">hadoop104:2888:3888</span></span><br></pre></td></tr></table></figure>

<p>（2）配置参数解读</p>
<p>Server.A=B:C:D。</p>
<p>A  是一个数字，表示这个是第几号服务器；</p>
<p>B  是这个服务器的IP地址；</p>
<p>C  是这个服务器与集群中的Leader服务器交换信息的端口；</p>
<p>D  是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
</li>
<li><p><strong>集群操作</strong></p>
<p>（1）在/opt/module/zookeeper-3.4.10/zkData目录下创建一个myid的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch myid</span><br></pre></td></tr></table></figure>

<p>​    添加myid文件，注意一定要在linux里面创建，在notepad++里面很可能乱码</p>
<p>（2）编辑myid文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi myid</span><br></pre></td></tr></table></figure>

<p>​    在文件中添加与server对应的编号：如2</p>
<p>（3）拷贝配置好的zookeeper到其他机器上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r zookeeper-3.4.10/ [root@hadoop103.atguigu.com:/opt/app/](mailto:root@hadoop103.atguigu.com:/opt/app/)</span><br><span class="line">scp -r zookeeper-3.4.10/ [root@hadoop104.atguigu.com:/opt/app/](mailto:root@hadoop104.atguigu.com:/opt/app/)</span><br></pre></td></tr></table></figure>

<p>​    并分别修改myid文件中内容为3、4</p>
<p>（4）分别启动zookeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.4.10]# bin/zkServer.sh start</span><br><span class="line">[root@hadoop103 zookeeper-3.4.10]# bin/zkServer.sh start</span><br><span class="line">[root@hadoop104 zookeeper-3.4.10]# bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>（5）查看状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.4.10]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">[root@hadoop103 zookeeper-3.4.10]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line">[root@hadoop104 zookeeper-3.4.5]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="配置-HDFS-HA-集群"><a href="#配置-HDFS-HA-集群" class="headerlink" title="配置 HDFS-HA 集群"></a>配置 HDFS-HA 集群</h2><ol>
<li><p><strong>官方地址： <a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></strong></p>
</li>
<li><p><strong>在 opt 目录下创建一个 ha 文件夹</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd /opt</span><br><span class="line">[atguigu@hadoop102 opt]$ sudo mkdir ha</span><br><span class="line">[atguigu@hadoop102 opt]$ sudo chown atguigu:atguigu /opt/ha</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>将/opt/module/下的 hadoop-3.1.3 拷贝到/opt/ha 目录下（记得删除 data 和 log 目录）</strong> </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 opt]$ cp -r /opt/module/hadoop-3.1.3 /opt/ha/</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>配置 core-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 把多个 NameNode 的地址组装成一个集群 mycluster --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hadoop 运行时产生文件的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/ha/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>配置 hdfs-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode 数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- DataNode 数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- JournalNode 数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 完全分布式集群名称 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 集群中 NameNode 节点都有哪些 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2,nn3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode 的 RPC 通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode 的 http 通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 NameNode 元数据在 JournalNode 上的存放位置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/myclus</span><br><span class="line">    ter<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 访问代理类： client 用于确定哪个 NameNode 为 Active --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyP</span><br><span class="line">    rovider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 使用隔离机制时需要 ssh 秘钥登录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/atguigu/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>分发配置好的 hadoop 环境到其他节点</strong></p>
</li>
</ol>
<h2 id="启动-HDFS-HA-集群"><a href="#启动-HDFS-HA-集群" class="headerlink" title="启动 HDFS-HA 集群"></a>启动 HDFS-HA 集群</h2><ol>
<li><p><strong>将 HADOOP_HOME 环境变量更改到 HA 目录(三台机器)</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>将 HADOOP_HOME 部分改为如下  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/ha/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>去三台机器上 source 环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$source /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>在各个 JournalNode 节点上，输入以下命令启动 journalnode 服务</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs --daemon start journalnode</span><br><span class="line">[atguigu@hadoop103 ~]$ hdfs --daemon start journalnode</span><br><span class="line">[atguigu@hadoop104 ~]$ hdfs --daemon start journalnode</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>在[nn1]上，对其进行格式化， 并启动</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs namenode -format</span><br><span class="line">[atguigu@hadoop102 ~]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>在[nn2]和[nn3]上，同步 nn1 的元数据信息</strong> </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ hdfs namenode -bootstrapStandby</span><br><span class="line">[atguigu@hadoop104 ~]$ hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动[nn2]和[nn3]</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ hdfs --daemon start namenode</span><br><span class="line">[atguigu@hadoop104 ~]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>查看 web 页面显示</strong></p>
<p><img src="/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812101937092.png" alt="image-20220812101937092"></p>
<p><img src="/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812120144955.png" alt="image-20220812120144955"></p>
</li>
<li><p><strong>在所有节点上，启动 datanode</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs --daemon start datanode</span><br><span class="line">[atguigu@hadoop103 ~]$ hdfs --daemon start datanode</span><br><span class="line">[atguigu@hadoop104 ~]$ hdfs --daemon start datanode</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>将[nn1]切换为 Active</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs haadmin -transitionToActive nn1</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>查看是否 Active</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs haadmin -getServiceState nn1</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h1 id="HDFS-HA-自动模式"><a href="#HDFS-HA-自动模式" class="headerlink" title="HDFS-HA 自动模式"></a>HDFS-HA 自动模式</h1><h2 id="HDFS-HA-自动故障转移工作机制"><a href="#HDFS-HA-自动故障转移工作机制" class="headerlink" title="HDFS-HA 自动故障转移工作机制"></a>HDFS-HA 自动故障转移工作机制</h2><p>自动故障转移为 HDFS 部署增加了两个新组件： ZooKeeper 和 ZKFailoverController（ZKFC）进程，如图所示。 ZooKeeper 是维护少量协调数据，通知客户端这些数据的改变和监视客户端故障的高可用服务。  </p>
<p><img src="/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812102335986.png" alt="image-20220812102335986"></p>
<h2 id="HDFS-HA-自动故障转移的集群规划"><a href="#HDFS-HA-自动故障转移的集群规划" class="headerlink" title="HDFS-HA 自动故障转移的集群规划"></a>HDFS-HA 自动故障转移的集群规划</h2><table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
</tr>
<tr>
<td>ZKFC</td>
<td>ZKFC</td>
<td>ZKFC</td>
</tr>
</tbody></table>
<h2 id="配置-HDFS-HA-自动故障转移"><a href="#配置-HDFS-HA-自动故障转移" class="headerlink" title="配置 HDFS-HA 自动故障转移"></a>配置 HDFS-HA 自动故障转移</h2><ol>
<li><p><strong>具体配置</strong></p>
<p>（1）在 hdfs-site.xml 中增加</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用 nn 故障自动转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）在 core-site.xml 文件中增加  </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（3）修改后分发配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 etc]$ pwd</span><br><span class="line">/opt/ha/hadoop-3.1.3/etc</span><br><span class="line">[atguigu@hadoop102 etc]$ xsync hadoop/</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动</strong></p>
<p>（1）关闭所有 HDFS 服务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ stop-dfs.sh</span><br></pre></td></tr></table></figure>

<p>（2）启动 Zookeeper 集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ zkServer.sh start</span><br><span class="line">[atguigu@hadoop103 ~]$ zkServer.sh start</span><br><span class="line">[atguigu@hadoop104 ~]$ zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>（3） 启动 Zookeeper 以后， 然后再初始化 HA 在 Zookeeper 中状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>

<p>（4）启动 HDFS 服务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>（ 5）可以去 zkCli.sh 客户端查看 Namenode 选举锁节点内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 7] get -s</span><br><span class="line">/hadoop-ha/mycluster/ActiveStandbyElectorLock</span><br><span class="line">myclusternn2 hadoop103 &gt;</span><br><span class="line">cZxid = 0x10000000b</span><br><span class="line">ctime = Tue Jul 14 17:00:13 CST 2020</span><br><span class="line">mZxid = 0x10000000b</span><br><span class="line">mtime = Tue Jul 14 17:00:13 CST 2020</span><br><span class="line">pZxid = 0x10000000b</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x40000da2eb70000</span><br><span class="line">dataLength = 33</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>验证</strong></p>
<p>(1）将 Active NameNode 进程 kill，查看网页端三台 Namenode 的状态变化  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">   [atguigu@hadoop102 ~]$ kill -9 namenode 的进程 id</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 解决 NN 连接不上 JN 的问题  </span></span></span><br><span class="line"></span><br><span class="line">自动故障转移配置好以后，然后使用 start-dfs.sh 群起脚本启动 hdfs 集群，有可能会遇到 NameNode 起来一会后，进程自动关闭的问题。查看 NameNode 日志，报错信息如下：  </span><br><span class="line"></span><br><span class="line">```properties</span><br><span class="line">2020-08-17 10:11:40,658 INFO org.apache.hadoop.ipc.Client: Retrying connect</span><br><span class="line">to server: hadoop104/192.168.6.104:8485. Already tried 0 time(s); retry</span><br><span class="line">policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10,</span><br><span class="line">sleepTime=1000 MILLISECONDS)</span><br><span class="line">2020-08-17 10:11:40,659 INFO org.apache.hadoop.ipc.Client: Retrying connect</span><br><span class="line">to server: hadoop102/192.168.6.102:8485. Already tried 0 time(s); retry</span><br><span class="line">policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10,</span><br><span class="line">sleepTime=1000 MILLISECONDS)</span><br><span class="line">2020-08-17 10:11:40,659 INFO org.apache.hadoop.ipc.Client: Retrying connect</span><br><span class="line">to server: hadoop103/192.168.6.103:8485. Already tried 0 time(s); retry</span><br><span class="line">policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10,</span><br><span class="line">sleepTime=1000 MILLISECONDS)</span><br><span class="line">2020-08-17 10:11:41,660 INFO org.apache.hadoop.ipc.Client: Retrying connect</span><br><span class="line">to server: hadoop104/192.168.6.104:8485. Already tried 1 time(s); retry</span><br><span class="line">policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10,</span><br><span class="line">sleepTime=1000 MILLISECONDS)</span><br><span class="line">... ...</span><br><span class="line">2020-08-17 10:11:49,676 INFO org.apache.hadoop.ipc.Client: Retrying connect</span><br><span class="line">to server: hadoop103/192.168.6.103:8485. Already tried 9 time(s); retry</span><br><span class="line">policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10,</span><br><span class="line">sleepTime=1000 MILLISECONDS)</span><br><span class="line">2020-08-17 10:11:49,678 WARN</span><br><span class="line">org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input</span><br><span class="line">streams from QJM to [192.168.6.102:8485, 192.168.6.103:8485,</span><br><span class="line">192.168.6.104:8485]. Skipping.</span><br><span class="line">org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many</span><br><span class="line">exceptions to achieve quorum size 2/3. 3 exceptions thrown:</span><br><span class="line">192.168.6.103:8485: Call From hadoop102/192.168.6.102 to hadoop103:8485</span><br><span class="line">failed on connection exception: java.net.ConnectException: 拒绝连接; For more</span><br><span class="line">details see: http://wiki.apache.org/hadoop/ConnectionRefused</span><br><span class="line">192.168.6.102:8485: Call From hadoop102/192.168.6.102 to hadoop102:8485</span><br><span class="line">failed on connection exception: java.net.ConnectException: 拒绝连接; For more</span><br><span class="line">details see: http://wiki.apache.org/hadoop/ConnectionRefused</span><br><span class="line">192.168.6.104:8485: Call From hadoop102/192.168.6.102 to hadoop104:8485</span><br><span class="line">failed on connection exception: java.net.ConnectException: 拒绝连接; For more</span><br><span class="line">details see: http://wiki.apache.org/hadoop/ConnectionRefused</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>查看报错日志，可分析出报错原因是因为 NameNode 连接不上 JournalNode，而利用 jps 命令查看到三台 JN 都已经正常启动，为什么 NN 还是无法正常连接到 JN 呢？这是因为 start-dfs.sh 群起脚本默认的启动顺序是先启动 NN，再启动 DN，然后再启动 JN，并且默认的 rpc 连接参数是重试次数为 10，每次重试的间隔是 1s，也就是说启动完 NN以后的 10s 中内， JN 还启动不起来， NN 就会报错了。  </p>
<p>core-default.xml 里面有两个参数如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- NN 连接 JN 重试次数，默认是 10 次 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.connect.max.retries<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 重试时间间隔，默认 1s --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.connect.retry.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>解决方案：遇到上述问题后，可以稍等片刻，等 JN 成功启动后，手动启动下三台NN：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs --daemon start namenode</span><br><span class="line">[atguigu@hadoop103 ~]$ hdfs --daemon start namenode</span><br><span class="line">[atguigu@hadoop104 ~]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>

<p>也可以在 core-site.xml 里面适当调大上面的两个参数：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- NN 连接 JN 重试次数，默认是 10 次 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.connect.max.retries<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>20<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 重试时间间隔，默认 1s --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.connect.retry.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>5000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="YARN-HA-配置"><a href="#YARN-HA-配置" class="headerlink" title="YARN-HA 配置"></a>YARN-HA 配置</h1><h2 id="YARN-HA-工作机制"><a href="#YARN-HA-工作机制" class="headerlink" title="YARN-HA 工作机制"></a>YARN-HA 工作机制</h2><ol>
<li><p><strong>官方文档：</strong></p>
<p><a href="http://hadoop.apache.org/docs/r3.1.3/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r3.1.3/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html</a></p>
</li>
<li><p><strong>YARN-HA 工作机制</strong></p>
<p><img src="/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812103242485.png" alt="image-20220812103242485"></p>
</li>
</ol>
<h2 id="配置-YARN-HA-集群"><a href="#配置-YARN-HA-集群" class="headerlink" title="配置 YARN-HA 集群"></a>配置 YARN-HA 集群</h2><ol>
<li><p><strong>环境准备</strong></p>
<p>（ 1）修改 IP<br>（ 2）修改主机名及主机名和 IP 地址的映射<br>（ 3）关闭防火墙<br>（ 4） ssh 免密登录<br>（ 5）安装 JDK，配置环境变量等<br>（ 6）配置 Zookeeper 集群</p>
</li>
<li><p><strong>规划集群</strong></p>
<table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>ResourceManager</td>
<td>ResourceManager</td>
<td>ResourceManager</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
</tr>
</tbody></table>
</li>
<li><p><strong>核心问题</strong></p>
<p>a .如果当前 active rm 挂了，其他 rm 怎么将其他 standby rm 上位核心原理跟 hdfs 一样，利用了 zk 的临时节点。<br>b. 当前 rm 上有很多的计算程序在等待运行,其他的 rm 怎么将这些程序接手过来接着跑 rm，会将当前的所有计算程序的状态存储在 zk 中,其他 rm 上位后会去读取，然后接着跑。</p>
</li>
<li><p><strong>具体配置</strong></p>
<p>（1） yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启用 resourcemanager ha --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 声明两台 resourcemanager 的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定 resourcemanager 的逻辑列表--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2,rm3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm1 的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的 web 端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的内部通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定供 NM 连接的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm2 的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm2 的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm3 的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的 web 端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的内部通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定供 NM 连接的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 zookeeper 集群的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启用自动恢复 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateSt</span><br><span class="line">    ore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLAS</span><br><span class="line">        SPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）同步更新其他节点的配置信息，分发配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 etc]$ xsync hadoop/</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动 YARN</strong></p>
<p>（1）在 hadoop102 或者 hadoop103 中执行：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>（2）查看服务状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ yarn rmadmin -getServiceState rm1</span><br></pre></td></tr></table></figure>

<p>（3）可以去 zkCli.sh 客户端查看 ResourceManager 选举锁节点内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ zkCli.sh</span><br><span class="line">[zk: localhost:2181(CONNECTED) 16] get -s</span><br><span class="line">/yarn-leader-election/cluster-yarn1/ActiveStandbyElectorLock</span><br><span class="line">cluster-yarn1rm1</span><br><span class="line">cZxid = 0x100000022</span><br><span class="line">ctime = Tue Jul 14 17:06:44 CST 2020</span><br><span class="line">mZxid = 0x100000022</span><br><span class="line">mtime = Tue Jul 14 17:06:44 CST 2020</span><br><span class="line">pZxid = 0x100000022</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x30000da33080005</span><br><span class="line">dataLength = 20</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>

<p>（ 4） web 端查看 hadoop102:8088 和 hadoop103:8088 的 YARN 的状态</p>
<p><img src="/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812104041183.png" alt="image-20220812104041183"></p>
</li>
</ol>
<h1 id="HADOOP-HA-的最终规划"><a href="#HADOOP-HA-的最终规划" class="headerlink" title="HADOOP HA 的最终规划"></a>HADOOP HA 的最终规划</h1><p>将整个 HA 搭建完成后,集群将形成以下模样</p>
<table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
</tr>
<tr>
<td>ZKFC</td>
<td>ZKFC</td>
<td>ZKFC</td>
</tr>
<tr>
<td>ResourceManager</td>
<td>ResourceManager</td>
<td>ResourceManager</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h1 id="HDFS-Federation架构设计"><a href="#HDFS-Federation架构设计" class="headerlink" title="HDFS Federation架构设计"></a><strong>HDFS</strong> Federation架构设计</h1><ol>
<li><p><strong>NameNode架构的局限性</strong></p>
<p>（1）Namespace（命名空间）的限制</p>
<p>由于NameNode在内存中存储所有的元数据（metadata），因此单个NameNode所能存储的对象（文件+块）数目受到NameNode所在JVM的heap size的限制。50G的heap能够存储20亿（200million）个对象，这20亿个对象支持4000个DataNode，12PB的存储（假设文件平均大小为40MB）。随着数据的飞速增长，存储的需求也随之增长。单个DataNode从4T增长到36T，集群的尺寸增长到8000个DataNode。存储的需求从12PB增长到大于100PB。</p>
<p>（2）隔离问题</p>
<p>由于HDFS仅有一个NameNode，无法隔离各个程序，因此HDFS上的一个实验程序就很有可能影响整个HDFS上运行的程序。</p>
<p>（3）性能的瓶颈</p>
<p>由于是单个NameNode的HDFS架构，因此整个HDFS文件系统的吞吐量受限于单个NameNode的吞吐量。</p>
</li>
<li><p><strong>HDFS Federation架构设计</strong></p>
<table>
<thead>
<tr>
<th>NameNode</th>
<th>NameNode</th>
<th>NameNode</th>
</tr>
</thead>
<tbody><tr>
<td>元数据</td>
<td>元数据</td>
<td>元数据</td>
</tr>
<tr>
<td>Log</td>
<td>machine</td>
<td>电商数据/话单数据</td>
</tr>
</tbody></table>
<p><img src="/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/image-20220812112950810.png" alt="image-20220812112950810"></p>
</li>
<li><p><strong>HDFS Federation应用思考</strong></p>
<p>不同应用可以使用不同NameNode进行数据管理，比如 图片业务、爬虫业务、日志审计业务。在Hadoop生态系统中，不同的框架使用不同的NameNode进行管理NameSpace。（隔离性）</p>
</li>
</ol>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Rui Zhang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2022/08/11/Hadoop%E4%B9%8BHA%E9%AB%98%E5%8F%AF%E7%94%A8/" title="Hadoop之HA高可用">http://yoursite.com/2022/08/11/Hadoop之HA高可用/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/08/08/Hadoop%E4%B9%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" rel="prev" title="Hadoop之源码解析">
      <i class="fa fa-chevron-left"></i> Hadoop之源码解析
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/08/12/Scala%E5%AD%A6%E4%B9%A0%E6%95%99%E7%A8%8B/" rel="next" title="Scala学习教程">
      Scala学习教程 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#HA概述"><span class="nav-number">1.</span> <span class="nav-text">HA概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS-HA-集群搭建"><span class="nav-number">2.</span> <span class="nav-text">HDFS-HA 集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-HA-核心问题"><span class="nav-number">2.1.</span> <span class="nav-text">HDFS-HA 核心问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS-HA-手动模式"><span class="nav-number">3.</span> <span class="nav-text">HDFS-HA 手动模式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#环境准备"><span class="nav-number">3.1.</span> <span class="nav-text">环境准备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#规划集群"><span class="nav-number">3.2.</span> <span class="nav-text">规划集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-Zookeeper-集群"><span class="nav-number">3.3.</span> <span class="nav-text">配置 Zookeeper 集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-HDFS-HA-集群"><span class="nav-number">3.4.</span> <span class="nav-text">配置 HDFS-HA 集群</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#启动-HDFS-HA-集群"><span class="nav-number">3.5.</span> <span class="nav-text">启动 HDFS-HA 集群</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS-HA-自动模式"><span class="nav-number">4.</span> <span class="nav-text">HDFS-HA 自动模式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-HA-自动故障转移工作机制"><span class="nav-number">4.1.</span> <span class="nav-text">HDFS-HA 自动故障转移工作机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-HA-自动故障转移的集群规划"><span class="nav-number">4.2.</span> <span class="nav-text">HDFS-HA 自动故障转移的集群规划</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-HDFS-HA-自动故障转移"><span class="nav-number">4.3.</span> <span class="nav-text">配置 HDFS-HA 自动故障转移</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#YARN-HA-配置"><span class="nav-number">5.</span> <span class="nav-text">YARN-HA 配置</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#YARN-HA-工作机制"><span class="nav-number">5.1.</span> <span class="nav-text">YARN-HA 工作机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#配置-YARN-HA-集群"><span class="nav-number">5.2.</span> <span class="nav-text">配置 YARN-HA 集群</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HADOOP-HA-的最终规划"><span class="nav-number">6.</span> <span class="nav-text">HADOOP HA 的最终规划</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#HDFS-Federation架构设计"><span class="nav-number">7.</span> <span class="nav-text">HDFS Federation架构设计</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Rui Zhang"
      src="/images/head.jpg">
  <p class="site-author-name" itemprop="name">Rui Zhang</p>
  <div class="site-description" itemprop="description">不在沉默中爆发，就在沉默中灭亡</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Rui Zhang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">1.7m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">25:10</span>
</div>




        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":120,"height":230},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
