<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="第1章 数据仓库概念数据仓库（ Data Warehouse ），是为企业制定决策，提供数据支持的。可以帮助企业，改进业务流程、提高产品质量等。 数据仓库的输入数据通常包括：业务数据、用户行为数据和爬虫数据等 业务数据：就是各行业在处理事务过程中产生的数据。比如用户在电商网站中登录、下单、支付等过程中，需要和网站后台数据库进行增删改查交互，产生的数据就是业务数据。业务数据通常存储在MySQL、Or">
<meta property="og:type" content="article">
<meta property="og:title" content="电商数仓项目-用户行为采集平台1">
<meta property="og:url" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/index.html">
<meta property="og:site_name" content="没有尾巴的小驴">
<meta property="og:description" content="第1章 数据仓库概念数据仓库（ Data Warehouse ），是为企业制定决策，提供数据支持的。可以帮助企业，改进业务流程、提高产品质量等。 数据仓库的输入数据通常包括：业务数据、用户行为数据和爬虫数据等 业务数据：就是各行业在处理事务过程中产生的数据。比如用户在电商网站中登录、下单、支付等过程中，需要和网站后台数据库进行增删改查交互，产生的数据就是业务数据。业务数据通常存储在MySQL、Or">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps2.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps3.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240731172445418.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240731172525083.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps4.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240802152318426.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240826171147114.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps6.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps7.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps8.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps9.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps10.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps2.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps3-1722582180804-1.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps4-1722582180804-2.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240802151126611.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps6.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps7.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps8.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps30.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps31.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps32.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps33.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps34.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps35.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps36.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps37.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps38.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps39.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps40.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps41.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps42.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps43.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps44.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps45.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps46.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps47.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps48.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps49.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps50.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps51.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps52.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps53.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1-1723016319645-1.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240809144458845.png">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1-1723016397748-3.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps2-1723016397748-4.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps3.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps4.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps7-1723017610125-9.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps8-1723017610125-10.jpg">
<meta property="og:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps9-1723102801713-1.png">
<meta property="article:published_time" content="2024-07-31T02:03:15.000Z">
<meta property="article:modified_time" content="2025-06-25T08:08:46.369Z">
<meta property="article:author" content="Rui Zhang">
<meta property="article:tag" content="数仓">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1.jpg">

<link rel="canonical" href="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>电商数仓项目-用户行为采集平台1 | 没有尾巴的小驴</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">没有尾巴的小驴</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">记录生活</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">22</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">22</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">52</span></a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.jpg">
      <meta itemprop="name" content="Rui Zhang">
      <meta itemprop="description" content="不在沉默中爆发，就在沉默中灭亡">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="没有尾巴的小驴">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          电商数仓项目-用户行为采集平台1
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-07-31 10:03:15" itemprop="dateCreated datePublished" datetime="2024-07-31T10:03:15+08:00">2024-07-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-06-25 16:08:46" itemprop="dateModified" datetime="2025-06-25T16:08:46+08:00">2025-06-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E4%BB%93/" itemprop="url" rel="index"><span itemprop="name">数仓</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>46k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>42 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="第1章-数据仓库概念"><a href="#第1章-数据仓库概念" class="headerlink" title="第1章 数据仓库概念"></a>第1章 数据仓库概念</h1><p>数据仓库（ Data Warehouse ），是为企业制定决策，提供数据支持的。可以帮助企业，改进业务流程、提高产品质量等。</p>
<p>数据仓库的输入数据通常包括：业务数据、用户行为数据和爬虫数据等</p>
<p>业务数据：就是各行业在处理事务过程中产生的数据。比如用户在电商网站中登录、下单、支付等过程中，需要和网站后台数据库进行增删改查交互，产生的数据就是业务数据。业务数据通常存储在MySQL、Oracle等数据库中。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1.jpg" alt="img"> </p>
<p>用户行为数据：用户在使用产品过程中，通过埋点收集与客户端产品交互过程中产生的数据，并发往日志服务器进行保存。比如页面浏览、点击、停留、评论、点赞、收藏等。用户行为数据通常存储在日志文件中。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps2.jpg" alt="img"> </p>
<p>爬虫数据：通常是通过技术手段获取其他公司网站的数据。不建议同学们这样去做。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps3.png" alt="img"></p>
<h1 id="第2章-项目需求及架构设计"><a href="#第2章-项目需求及架构设计" class="headerlink" title="第2章 项目需求及架构设计"></a>第2章 项目需求及架构设计</h1><h2 id="2-1-项目需求分析"><a href="#2-1-项目需求分析" class="headerlink" title="2.1 项目需求分析"></a>2.1 项目需求分析</h2><p>1）采集平台</p>
<p>​    （1）用户行为数据采集平台搭建</p>
<p>​    （2）业务数据采集平台搭建</p>
<p>2）离线需求</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240731172445418.png" alt="image-20240731172445418"></p>
<p>3）实时需求</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240731172525083.png" alt="image-20240731172525083"></p>
<p>4）思考题</p>
<p>（1）项目技术如何选型？</p>
<p>（2）框架版本如何选型（Apache、CDH、HDP）</p>
<p>（3）服务器使用物理机还是云主机？</p>
<p>（4）如何确认集群规模？（假设每台服务器16T硬盘）</p>
<h2 id="2-2-项目框架"><a href="#2-2-项目框架" class="headerlink" title="2.2 项目框架"></a>2.2 项目框架</h2><h3 id="2-2-1-技术选型"><a href="#2-2-1-技术选型" class="headerlink" title="2.2.1 技术选型"></a>2.2.1 技术选型</h3><p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps4.png" alt="img"></p>
<h3 id="2-2-2-系统数据流程设计"><a href="#2-2-2-系统数据流程设计" class="headerlink" title="2.2.2 系统数据流程设计"></a>2.2.2 系统数据流程设计</h3><p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240802152318426.png" alt="image-20240802152318426"></p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240826171147114.png" alt="image-20240826171147114"></p>
<h3 id="2-2-3-框架版本选型"><a href="#2-2-3-框架版本选型" class="headerlink" title="2.2.3 框架版本选型"></a>2.2.3 框架版本选型</h3><p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps6.png" alt="img"></p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps7.png" alt="img"></p>
<h3 id="2-2-4-服务器选型"><a href="#2-2-4-服务器选型" class="headerlink" title="2.2.4 服务器选型"></a>2.2.4 服务器选型</h3><p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps8.png" alt="img"></p>
<h3 id="2-2-5-集群规模"><a href="#2-2-5-集群规模" class="headerlink" title="2.2.5 集群规模"></a>2.2.5 集群规模</h3><p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps9.png" alt="img"></p>
<h3 id="2-2-6-集群资源规划设计"><a href="#2-2-6-集群资源规划设计" class="headerlink" title="2.2.6 集群资源规划设计"></a>2.2.6 集群资源规划设计</h3><p>在企业中通常会搭建一套生产集群和一套测试集群。生产集群运行生产任务，测试集群用于上线前代码编写和测试。</p>
<p>1）生产集群</p>
<p>（1）参考腾讯云EMR官方推荐部署</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps10.jpg" alt="img"> </p>
<ul>
<li><p>Master节点：管理节点，保证集群的调度正常进行；主要部署NameNode、ResourceManager、HMaster 等进程；非 HA 模式下数量为1，HA 模式下数量为2。</p>
</li>
<li><p>Core节点：为计算及存储节点，您在 HDFS 中的数据全部存储于 core 节点中，因此为了保证数据安全，扩容 core 节点后不允许缩容；主要部署 DataNode、NodeManager、RegionServer 等进程。非 HA 模式下数量≥2，HA 模式下数量≥3。</p>
</li>
<li><p>Common 节点：为 HA 集群 Master 节点提供数据共享同步以及高可用容错服务；主要部署分布式协调器组件，如 ZooKeeper、JournalNode 等节点。非HA模式数量为0，HA 模式下数量≥3。</p>
</li>
</ul>
<p>（2）消耗内存的分开部署</p>
<p>（3）数据传输数据比较紧密的放在一起（Kafka、clickhouse）</p>
<p>（4）客户端尽量放在一到两台服务器上，方便外部访问</p>
<p>（5）有依赖关系的尽量放到同一台服务器（例如：Ds-worker和hive/spark）</p>
<table>
<thead>
<tr>
<th>Master</th>
<th>Master</th>
<th>core</th>
<th>core</th>
<th>core</th>
<th>common</th>
<th>common</th>
<th>common</th>
</tr>
</thead>
<tbody><tr>
<td>nn</td>
<td>nn</td>
<td>dn</td>
<td>dn</td>
<td>dn</td>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>rm</td>
<td>rm</td>
<td>nm</td>
<td>nm</td>
<td>nm</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>zk</td>
<td>zk</td>
<td>zk</td>
</tr>
<tr>
<td>hive</td>
<td>hive</td>
<td>hive</td>
<td>hive</td>
<td>hive</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>kafka</td>
<td>kafka</td>
<td>kafka</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>spark</td>
<td>spark</td>
<td>spark</td>
<td>spark</td>
<td>spark</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>datax</td>
<td>datax</td>
<td>datax</td>
<td>datax</td>
<td>datax</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ds-master</td>
<td>Ds-master</td>
<td>Ds-worker</td>
<td>Ds-worker</td>
<td>Ds-worker</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>maxwell</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>superset</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>mysql</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>flume</td>
<td>flume</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>flink</td>
<td>flink</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>clickhouse</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>redis</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>hbase</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>2）测试集群服务器规划</p>
<table>
<thead>
<tr>
<th>服务名称</th>
<th>子服务</th>
<th>服务器hadoop102</th>
<th>服务器hadoop103</th>
<th>服务器hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>DataNode</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td></td>
<td>SecondaryNameNode</td>
<td></td>
<td></td>
<td>√</td>
</tr>
<tr>
<td>Yarn</td>
<td>NodeManager</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td></td>
<td>Resourcemanager</td>
<td></td>
<td>√</td>
<td></td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Zookeeper Server</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>Flume（采集日志）</td>
<td>Flume</td>
<td>√</td>
<td>√</td>
<td></td>
</tr>
<tr>
<td>Kafka</td>
<td>Kafka</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>Flume（消费Kafka日志）</td>
<td>Flume</td>
<td></td>
<td></td>
<td>√</td>
</tr>
<tr>
<td>Flume（消费Kafka业务）</td>
<td>Flume</td>
<td></td>
<td></td>
<td>√</td>
</tr>
<tr>
<td>Hive</td>
<td></td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>MySQL</td>
<td>MySQL</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>DataX</td>
<td></td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>Spark</td>
<td></td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>DolphinScheduler</td>
<td>ApiApplicationServer</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>AlertServer</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>MasterServer</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>WorkerServer</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td></td>
<td>LoggerServer</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>Superset</td>
<td>Superset</td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Flink</td>
<td></td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ClickHouse</td>
<td></td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Redis</td>
<td></td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Hbase</td>
<td></td>
<td>√</td>
<td></td>
<td></td>
</tr>
<tr>
<td>服务数总计</td>
<td></td>
<td>20</td>
<td>11</td>
<td>12</td>
</tr>
</tbody></table>
<h1 id="第3章-用户行为日志"><a href="#第3章-用户行为日志" class="headerlink" title="第3章 用户行为日志"></a>第3章 用户行为日志</h1><h2 id="3-1-用户行为日志概述"><a href="#3-1-用户行为日志概述" class="headerlink" title="3.1 用户行为日志概述"></a>3.1 用户行为日志概述</h2><p>用户行为日志的内容，主要包括用户的各项行为信息以及行为所处的环境信息。收集这些信息的主要目的是优化产品和为各项分析统计指标提供数据支撑。收集这些信息的手段通常为埋点。</p>
<p>目前主流的埋点方式，有代码埋点（前端/后端）、可视化埋点、全埋点等。</p>
<p>代码埋点是通过调用埋点SDK函数，在需要埋点的业务逻辑功能位置调用接口，上报埋点数据。例如，我们对页面中的某个按钮埋点后，当这个按钮被点击时，可以在这个按钮对应的 OnClick 函数里面调用SDK提供的数据发送接口，来发送数据。</p>
<p>可视化埋点只需要研发人员集成采集 SDK，不需要写埋点代码，业务人员就可以通过访问分析平台的“圈选”功能，来“圈”出需要对用户行为进行捕捉的控件，并对该事件进行命名。圈选完毕后，这些配置会同步到各个用户的终端上，由采集 SDK 按照圈选的配置自动进行用户行为数据的采集和发送。</p>
<p>全埋点是通过在产品中嵌入SDK，前端自动采集页面上的全部用户行为事件，上报埋点数据，相当于做了一个统一的埋点。然后再通过界面配置哪些数据需要在系统里面进行分析。</p>
<h2 id="3-2-用户行为日志内容"><a href="#3-2-用户行为日志内容" class="headerlink" title="3.2 用户行为日志内容"></a>3.2 用户行为日志内容</h2><p>本项目收集和分析的用户行为信息主要有页面浏览记录、动作记录、曝光记录、启动记录和错误记录。</p>
<h3 id="3-2-1-页面浏览记录"><a href="#3-2-1-页面浏览记录" class="headerlink" title="3.2.1 页面浏览记录"></a>3.2.1 页面浏览记录</h3><p>页面浏览记录，记录的是访客对页面的浏览行为，该行为的环境信息主要有用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息及页面信息等。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1.png" alt="img"></p>
<h3 id="3-2-2-动作记录"><a href="#3-2-2-动作记录" class="headerlink" title="3.2.2 动作记录"></a>3.2.2 动作记录</h3><p>动作记录，记录的是用户的业务操作行为，该行为的环境信息主要有用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息 及动作目标对象信息等。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps2.png" alt="img"></p>
<h3 id="3-2-3-曝光记录"><a href="#3-2-3-曝光记录" class="headerlink" title="3.2.3 曝光记录"></a>3.2.3 曝光记录</h3><p>曝光记录，记录的是曝光行为，该行为的环境信息主要有用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息及曝光对象信息等。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps3-1722582180804-1.png" alt="img"></p>
<h3 id="3-2-4-启动记录"><a href="#3-2-4-启动记录" class="headerlink" title="3.2.4 启动记录"></a>3.2.4 启动记录</h3><p>启动记录，记录的是用户启动应用的行为，该行为的环境信息主要有用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息、启动类型及开屏广告信息等。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps4-1722582180804-2.png" alt="img"></p>
<h3 id="3-2-5-错误记录"><a href="#3-2-5-错误记录" class="headerlink" title="3.2.5 错误记录"></a>3.2.5 错误记录</h3><p>错误记录，记录的是用户在使用应用过程中的报错行为，该行为的环境信息主要有用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息、以及可能与报错相关的页面信息、动作信息、曝光信息和动作信息。</p>
<h2 id="3-3-用户行为日志格式"><a href="#3-3-用户行为日志格式" class="headerlink" title="3.3 用户行为日志格式"></a>3.3 用户行为日志格式</h2><p>我们的日志结构大致可分为两类，一是页面日志，二是启动日志。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240802151126611.png" alt="image-20240802151126611"></p>
<h3 id="3-3-1-页面日志"><a href="#3-3-1-页面日志" class="headerlink" title="3.3.1 页面日志"></a>3.3.1 页面日志</h3><p>页面日志，以页面浏览为单位，即一个页面浏览记录，生成一条页面埋点日志。一条完整的页面日志包含，一个页面浏览记录，若干个用户在该页面所做的动作记录，若干个该页面的曝光记录，以及一个在该页面发生的报错记录。除上述行为信息，页面日志还包含了这些行为所处的各种环境信息，包括用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息等。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	"common": &#123;                      -- 环境信息</span><br><span class="line">		"ar": "15",                 -- 省份ID </span><br><span class="line">		"ba": "iPhone",             -- 手机品牌</span><br><span class="line">		"ch": "Appstore",           -- 渠道</span><br><span class="line">		"is_new": "1",              -- 是否首日使用，首次使用的当日，该字段值为1，过了24:00，该字段置为0。</span><br><span class="line">		"md": "iPhone 8",           -- 手机型号</span><br><span class="line">		"mid": "YXfhjAYH6As2z9Iq",  -- 设备id</span><br><span class="line">		"os": "iOS 13.2.9",         -- 操作系统</span><br><span class="line">		"sid": "3981c171-558a-437c-be10-da6d2553c517",     -- 会话id</span><br><span class="line">		"uid": "485",               -- 会员id</span><br><span class="line">		"vc": "v2.1.134"            -- app版本号</span><br><span class="line">	&#125;,</span><br><span class="line">	"actions": [&#123;                    -- 动作(事件)</span><br><span class="line">		"action_id": "favor_add",   -- 动作id</span><br><span class="line">		"item": "3",                -- 目标id</span><br><span class="line">		"item_type": "sku_id",      -- 目标类型</span><br><span class="line">		"ts": 1585744376605         -- 动作时间戳</span><br><span class="line">	    &#125;</span><br><span class="line">	],</span><br><span class="line">	"displays": [&#123;                   -- 曝光</span><br><span class="line">			"displayType": "query", -- 曝光类型</span><br><span class="line">			"item": "3",            -- 曝光对象id</span><br><span class="line">			"item_type": "sku_id",  -- 曝光对象类型</span><br><span class="line">			"order": 1,             -- 出现顺序</span><br><span class="line">			"pos_id": 2,            -- 曝光位置</span><br><span class="line">			"pos_seq": 1            -- 曝光序列号（同一坑位多个对象的编号）</span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="attr">"displayType"</span>: <span class="string">"promotion"</span>,</span><br><span class="line">			<span class="attr">"item"</span>: <span class="string">"6"</span>,</span><br><span class="line">			<span class="attr">"item_type"</span>: <span class="string">"sku_id"</span>,</span><br><span class="line">			<span class="attr">"order"</span>: <span class="number">2</span>,</span><br><span class="line">			<span class="attr">"pos_id"</span>: <span class="number">1</span>,</span><br><span class="line">             <span class="attr">"pos_seq"</span>: <span class="number">1</span></span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="attr">"displayType"</span>: <span class="string">"promotion"</span>,</span><br><span class="line">			<span class="attr">"item"</span>: <span class="string">"9"</span>,</span><br><span class="line">			<span class="attr">"item_type"</span>: <span class="string">"sku_id"</span>,</span><br><span class="line">			<span class="attr">"order"</span>: <span class="number">3</span>,</span><br><span class="line">			<span class="attr">"pos_id"</span>: <span class="number">3</span>,</span><br><span class="line">             <span class="attr">"pos_seq"</span>: <span class="number">1</span></span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="attr">"displayType"</span>: <span class="string">"recommend"</span>,</span><br><span class="line">			<span class="attr">"item"</span>: <span class="string">"6"</span>,</span><br><span class="line">			<span class="attr">"item_type"</span>: <span class="string">"sku_id"</span>,</span><br><span class="line">			<span class="attr">"order"</span>: <span class="number">4</span>,</span><br><span class="line">			<span class="attr">"pos_id"</span>: <span class="number">2</span>,</span><br><span class="line">			<span class="attr">"pos_seq"</span>: <span class="number">1</span></span><br><span class="line">		&#125;,</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="attr">"displayType"</span>: <span class="string">"query "</span>,</span><br><span class="line">			<span class="attr">"item"</span>: <span class="string">"6"</span>,</span><br><span class="line">			<span class="attr">"item_type"</span>: <span class="string">"sku_id"</span>,</span><br><span class="line">			<span class="attr">"order"</span>: <span class="number">5</span>,</span><br><span class="line">			<span class="attr">"pos_id"</span>: <span class="number">1</span>,</span><br><span class="line">			<span class="attr">"pos_seq"</span>: <span class="number">1</span></span><br><span class="line">		&#125;</span><br><span class="line">	],</span><br><span class="line">	"page": &#123;                          -- 页面信息</span><br><span class="line">		"during_time": 7648,           -- 持续时间毫秒</span><br><span class="line">		"item": "3", 	               -- 目标id</span><br><span class="line">		"item_type": "sku_id",         -- 目标类型</span><br><span class="line">		"last_page_id": "login",       -- 上页ID</span><br><span class="line">		"page_id": "good_detail",      -- 页面ID</span><br><span class="line">		"from_pos_id":999,           -- 来源坑位ID</span><br><span class="line">         "from_pos_seq":999,           -- 来源坑位序列号</span><br><span class="line">         "refer_id":"2",			  -- 外部营销渠道ID</span><br><span class="line">		"sourceType": "promotion"      -- 来源类型</span><br><span class="line">	&#125;,                                 </span><br><span class="line">	"err": &#123;                           --错误</span><br><span class="line">		"error_code": "1234",          --错误码</span><br><span class="line">		"msg": ""           --错误信息</span><br><span class="line">	&#125;,                                 </span><br><span class="line">	"ts": 1585744374423                --跳入时间戳</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-2-启动日志"><a href="#3-3-2-启动日志" class="headerlink" title="3.3.2 启动日志"></a>3.3.2 启动日志</h3><p>启动日志以启动为单位，及一次启动行为，生成一条启动日志。一条完整的启动日志包括一个启动记录，一个本次启动时的报错记录，以及启动时所处的环境信息，包括用户信息、时间信息、地理位置信息、设备信息、应用信息、渠道信息等。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"common"</span>: &#123;</span><br><span class="line">    <span class="attr">"ar"</span>: <span class="string">"370000"</span>,</span><br><span class="line">    <span class="attr">"ba"</span>: <span class="string">"Honor"</span>,</span><br><span class="line">    <span class="attr">"ch"</span>: <span class="string">"wandoujia"</span>,</span><br><span class="line">    <span class="attr">"is_new"</span>: <span class="string">"1"</span>,</span><br><span class="line">    <span class="attr">"md"</span>: <span class="string">"Honor 20s"</span>,</span><br><span class="line">    <span class="attr">"mid"</span>: <span class="string">"eQF5boERMJFOujcp"</span>,</span><br><span class="line">	<span class="attr">"os"</span>: <span class="string">"Android 11.0"</span>,</span><br><span class="line">	<span class="attr">"sid"</span>:<span class="string">"a1068e7a-e25b-45dc-9b9a-5a55ae83fc81"</span>,</span><br><span class="line">    <span class="attr">"uid"</span>: <span class="string">"76"</span>,</span><br><span class="line">    <span class="attr">"vc"</span>: <span class="string">"v2.1.134"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"start"</span>: &#123;   </span><br><span class="line">     "entry": "icon",         	--icon手机图标  notice 通知   install 安装后启动</span><br><span class="line">     "loading_time": 18803,   	--启动加载时间</span><br><span class="line">     "open_ad_id": 7,         	--广告页ID</span><br><span class="line">     "open_ad_ms": 3449,      	-- 广告总共播放时间</span><br><span class="line">     "open_ad_skip_ms": 1989  	--  用户跳过广告时点</span><br><span class="line">  &#125;,</span><br><span class="line">  "err":&#123;                       --错误</span><br><span class="line">     "error_code": "1234",      --错误码</span><br><span class="line">     "msg": ""       --错误信息</span><br><span class="line">   &#125;,</span><br><span class="line">  "ts": 1585744304000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-4-服务器和JDK准备"><a href="#3-4-服务器和JDK准备" class="headerlink" title="3.4 服务器和JDK准备"></a>3.4 服务器和JDK准备</h2><h3 id="3-4-1-服务器准备"><a href="#3-4-1-服务器准备" class="headerlink" title="3.4.1 服务器准备"></a>3.4.1 服务器准备</h3><p>安装如下文档配置步骤，分别安装hadoop102、hadoop103、hadoop104三台主机。</p>
<p>Hadoop运行环境搭建</p>
<h4 id="3-4-1-1-模板虚拟机环境准备"><a href="#3-4-1-1-模板虚拟机环境准备" class="headerlink" title="3.4.1.1 模板虚拟机环境准备"></a>3.4.1.1 模板虚拟机环境准备</h4><p>0）安装模板虚拟机，IP地址192.168.10.100、主机名称hadoop100、内存4G、硬盘50G</p>
<p>1）hadoop100虚拟机配置要求如下（本文Linux系统全部以CentOS-7.5-x86-1804为例）</p>
<p>（1）使用yum安装需要虚拟机可以正常上网，yum安装前可以先测试下虚拟机联网情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# ping www.baidu.com</span><br><span class="line">PING www.baidu.com (14.215.177.39) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=128 time=8.60 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=128 time=7.72 ms</span><br></pre></td></tr></table></figure>

<p>（2）安装epel-release</p>
<p>注：Extra Packages for Enterprise Linux是为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux。相当于是一个软件仓库，大多数rpm包在官方 repository 中是找不到的）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y epel-release</span><br></pre></td></tr></table></figure>

<p>（3）注意：如果Linux安装的是最小系统版，还需要安装如下工具；如果安装的是Linux桌面标准版，不需要执行如下操作</p>
<ul>
<li>net-tool：工具包集合，包含ifconfig等命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y net-tools</span><br></pre></td></tr></table></figure>

<ul>
<li>vim：编辑器</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y vim</span><br></pre></td></tr></table></figure>

<p>2）关闭防火墙，关闭防火墙开机自启</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# systemctl stop firewalld</span><br><span class="line">[root@hadoop100 ~]# systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<p>​    注意：在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安全的防火墙。</p>
<p>3）创建atguigu用户，并修改atguigu用户的密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# useradd atguigu</span><br><span class="line">[root@hadoop100 ~]# passwd atguigu</span><br></pre></td></tr></table></figure>

<p>4）配置atguigu用户具有root权限，方便后期加sudo执行root权限的命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# vim /etc/sudoers</span><br></pre></td></tr></table></figure>

<p>修改/etc/sudoers文件，在%wheel这行下面添加一行，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere</span></span></span><br><span class="line">root    ALL=(ALL)     ALL</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allows people in group wheel to run all commands</span></span></span><br><span class="line"><span class="meta">%</span><span class="bash">wheel  ALL=(ALL)       ALL</span></span><br><span class="line">atguigu   ALL=(ALL)     NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>注意：atguigu这一行不要直接放到root行下面，因为所有用户都属于wheel组，你先配置了atguigu具有免密功能，但是程序执行到%wheel行时，该功能又被覆盖回需要密码。所以atguigu要放到%wheel这行下面。</p>
<p>5）在/opt目录下创建文件夹，并修改所属主和所属组</p>
<p>（1）在/opt目录下创建module、software文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# mkdir /opt/module</span><br><span class="line">[root@hadoop100 ~]# mkdir /opt/software</span><br></pre></td></tr></table></figure>

<p>（2）修改module、software文件夹的所有者和所属组均为atguigu用户 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# chown atguigu:atguigu /opt/module </span><br><span class="line">[root@hadoop100 ~]# chown atguigu:atguigu /opt/software</span><br></pre></td></tr></table></figure>

<p>（3）查看module、software文件夹的所有者和所属组</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# cd /opt/</span><br><span class="line">[root@hadoop100 opt]# ll</span><br><span class="line">总用量 12</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 module</span><br><span class="line">drwxr-xr-x. 2 root    root    4096 9月   7 2017 rh</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 software</span><br></pre></td></tr></table></figure>

<p>6）卸载虚拟机自带的JDK</p>
<p>​    注意：如果你的虚拟机是最小化安装不需要执行这一步。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<ul>
<li><p>rpm -qa：查询所安装的所有rpm软件包</p>
</li>
<li><p>grep -i：忽略大小写</p>
</li>
<li><p>xargs -n1：表示每次只传递一个参数</p>
</li>
<li><p>rpm -e –nodeps：强制卸载软件</p>
</li>
</ul>
<p>7）重启虚拟机</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# reboot</span><br></pre></td></tr></table></figure>

<h4 id="3-4-1-2-克隆虚拟机"><a href="#3-4-1-2-克隆虚拟机" class="headerlink" title="3.4.1.2 克隆虚拟机"></a>3.4.1.2 克隆虚拟机</h4><p>1）利用模板机hadoop100，克隆三台虚拟机：hadoop102、hadoop103、hadoop104</p>
<p>​    注意：克隆时，要先关闭hadoop100。</p>
<p>2）修改克隆机IP，以下以hadoop102举例说明</p>
<p>（1）修改克隆虚拟机的静态IP</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]# sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<p>改成</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">DEVICE</span>=<span class="string">ens33</span></span><br><span class="line"><span class="attr">TYPE</span>=<span class="string">Ethernet</span></span><br><span class="line"><span class="attr">ONBOOT</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">BOOTPROTO</span>=<span class="string">static</span></span><br><span class="line"><span class="attr">NAME</span>=<span class="string">"ens33"</span></span><br><span class="line"><span class="attr">IPADDR</span>=<span class="string">192.168.10.102</span></span><br><span class="line"><span class="attr">PREFIX</span>=<span class="string">24</span></span><br><span class="line"><span class="attr">GATEWAY</span>=<span class="string">192.168.10.2</span></span><br><span class="line"><span class="attr">DNS1</span>=<span class="string">192.168.10.2</span></span><br></pre></td></tr></table></figure>

<p>（2）查看Linux虚拟机的虚拟网络编辑器，编辑-&gt;虚拟网络编辑器-&gt;VMnet8</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps6.jpg" alt="img"> </p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps7.jpg" alt="img"> </p>
<p>（3）查看Windows系统适配器VMware Network Adapter VMnet8的IP地址</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps8.jpg" alt="img"> </p>
<p>（4）保证Linux系统ifcfg-ens33文件中IP地址、虚拟网络编辑器地址和Windows系统VM8网络IP地址相同。</p>
<p>3）修改克隆机主机名，以下以hadoop102举例说明</p>
<p>（1）修改主机名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]# sudo vim /etc/hostname</span><br><span class="line">hadoop102</span><br></pre></td></tr></table></figure>

<p>（2）配置Linux克隆机主机名称映射hosts文件，打开/etc/hosts</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]# sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>

<p>添加如下内容</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">192.168.10.100</span> <span class="string">hadoop100</span></span><br><span class="line"><span class="meta">192.168.10.101</span> <span class="string">hadoop101</span></span><br><span class="line"><span class="meta">192.168.10.102</span> <span class="string">hadoop102</span></span><br><span class="line"><span class="meta">192.168.10.103</span> <span class="string">hadoop103</span></span><br><span class="line"><span class="meta">192.168.10.104</span> <span class="string">hadoop104</span></span><br><span class="line"><span class="meta">192.168.10.105</span> <span class="string">hadoop105</span></span><br><span class="line"><span class="meta">192.168.10.106</span> <span class="string">hadoop106</span></span><br><span class="line"><span class="meta">192.168.10.107</span> <span class="string">hadoop107</span></span><br><span class="line"><span class="meta">192.168.10.108</span> <span class="string">hadoop108</span></span><br></pre></td></tr></table></figure>

<p>4）重启克隆机hadoop102 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop100 ~]# sudo reboot</span><br></pre></td></tr></table></figure>

<p>5）修改windows的主机映射文件（hosts文件）</p>
<p>（1）如果操作系统是window7，可以直接修改 </p>
<ol>
<li><p>进入<code>C:Windows/System32/drivers/etc</code>路径</p>
</li>
<li><p>打开hosts文件并添加如下内容，然后保存</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">192.168.10.100</span> <span class="string">hadoop100</span></span><br><span class="line"><span class="meta">192.168.10.101</span> <span class="string">hadoop101</span></span><br><span class="line"><span class="meta">192.168.10.102</span> <span class="string">hadoop102</span></span><br><span class="line"><span class="meta">192.168.10.103</span> <span class="string">hadoop103</span></span><br><span class="line"><span class="meta">192.168.10.104</span> <span class="string">hadoop104</span></span><br><span class="line"><span class="meta">192.168.10.105</span> <span class="string">hadoop105</span></span><br><span class="line"><span class="meta">192.168.10.106</span> <span class="string">hadoop106</span></span><br><span class="line"><span class="meta">192.168.10.107</span> <span class="string">hadoop107</span></span><br><span class="line"><span class="meta">192.168.10.108</span> <span class="string">hadoop108</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>（2）如果操作系统是window10，先拷贝出来，修改保存以后，再覆盖即可</p>
<ol>
<li><p>进入C:WindowsSystem32driversetc路径</p>
</li>
<li><p>拷贝hosts文件到桌面</p>
</li>
<li><p>打开桌面hosts文件并添加如下内容</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">192.168.10.100</span> <span class="string">hadoop100</span></span><br><span class="line"><span class="meta">192.168.10.101</span> <span class="string">hadoop101</span></span><br><span class="line"><span class="meta">192.168.10.102</span> <span class="string">hadoop102</span></span><br><span class="line"><span class="meta">192.168.10.103</span> <span class="string">hadoop103</span></span><br><span class="line"><span class="meta">192.168.10.104</span> <span class="string">hadoop104</span></span><br><span class="line"><span class="meta">192.168.10.105</span> <span class="string">hadoop105</span></span><br><span class="line"><span class="meta">192.168.10.106</span> <span class="string">hadoop106</span></span><br><span class="line"><span class="meta">192.168.10.107</span> <span class="string">hadoop107</span></span><br><span class="line"><span class="meta">192.168.10.108</span> <span class="string">hadoop108</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将桌面hosts文件覆盖C:WindowsSystem32driversetc路径hosts文件</p>
</li>
</ol>
<h3 id="3-4-2-阿里云服务器准备（可选）"><a href="#3-4-2-阿里云服务器准备（可选）" class="headerlink" title="3.4.2 阿里云服务器准备（可选）"></a>3.4.2 阿里云服务器准备（可选）</h3><h4 id="3-4-2-1-注册阿里云账户"><a href="#3-4-2-1-注册阿里云账户" class="headerlink" title="3.4.2.1 注册阿里云账户"></a>3.4.2.1 注册阿里云账户</h4><p>阿里云网址为：<a href="https://cn.aliyun.com/，注册账号并登录。" target="_blank" rel="noopener">https://cn.aliyun.com/，注册账号并登录。</a></p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps30.jpg" alt="img"> </p>
<h4 id="3-4-2-2-购买ECS云服务器"><a href="#3-4-2-2-购买ECS云服务器" class="headerlink" title="3.4.2.2 购买ECS云服务器"></a>3.4.2.2 购买ECS云服务器</h4><p>1）进入控制台</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps31.jpg" alt="img"> </p>
<p>2）打开侧边栏，点击云服务器ECS</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps32.jpg" alt="img"> </p>
<p>3）侧边栏点击实例，然后点击创建实例</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps33.jpg" alt="img"> </p>
<p>4）选择计费方式、服务器区域</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps34.jpg" alt="img"> </p>
<p>5）选定服务器配置</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps35.jpg" alt="img"> </p>
<p>6）选定服务器系统</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps36.jpg" alt="img"> </p>
<p>7）选定磁盘类型及大小</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps37.jpg" alt="img"></p>
<p>8)网络和安全组配置</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps38.jpg" alt="img"> </p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps39.jpg" alt="img"> </p>
<p>9）系统配置</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps40.jpg" alt="img"> </p>
<p>10）分组设置，默认即可</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps41.jpg" alt="img"> </p>
<p>11）确认订单</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps42.jpg" alt="img"> </p>
<h4 id="3-4-2-3-ECS配置及安全组修改"><a href="#3-4-2-3-ECS配置及安全组修改" class="headerlink" title="3.4.2.3 ECS配置及安全组修改"></a>3.4.2.3 ECS配置及安全组修改</h4><p>1）升级hadoop102配置</p>
<p>（1）停止实例</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps43.jpg" alt="img"> </p>
<p>（2）更改实例规格</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps44.jpg" alt="img"> </p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps45.jpg" alt="img"> </p>
<p>2）修改安全组策略</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps46.jpg" alt="img"> </p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps47.jpg" alt="img"> </p>
<p>需将以下端口开放。</p>
<table>
<thead>
<tr>
<th>服务</th>
<th>端口</th>
</tr>
</thead>
<tbody><tr>
<td>Cloudera Manager Server（WebUI）</td>
<td>7180</td>
</tr>
<tr>
<td>HDFS NameNode（WebUI）</td>
<td>9870</td>
</tr>
<tr>
<td>Yarn ResourceManager（WebUI）</td>
<td>8088</td>
</tr>
<tr>
<td>JobHistory Server（WebUI）</td>
<td>19888</td>
</tr>
<tr>
<td>HBase Master（WebUI）</td>
<td>16010</td>
</tr>
<tr>
<td>HiveServer2 （WebUI）</td>
<td>10002</td>
</tr>
<tr>
<td>HUE Server（WebUI）</td>
<td>8888/8889</td>
</tr>
<tr>
<td>Oozie Server</td>
<td>11000</td>
</tr>
<tr>
<td>Sentry Server</td>
<td>51000</td>
</tr>
<tr>
<td>Spark Master/Worker/History Server</td>
<td>18080/18081/18088</td>
</tr>
<tr>
<td>Kerberos</td>
<td>88</td>
</tr>
<tr>
<td>MySQL</td>
<td>3306</td>
</tr>
</tbody></table>
<h4 id="3-4-2-4-连接阿里云服务器"><a href="#3-4-2-4-连接阿里云服务器" class="headerlink" title="3.4.2.4 连接阿里云服务器"></a>3.4.2.4 连接阿里云服务器</h4><p>打开远程连接工具进行配置，这里以CRT为例。</p>
<p>1）新建一个session</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps48.jpg" alt="img"> </p>
<p>2）填写hostname（填写公网ip）</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps49.jpg" alt="img"> </p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps50.jpg" alt="img"> </p>
<h4 id="3-4-2-5-修改服务器hosts文件"><a href="#3-4-2-5-修改服务器hosts文件" class="headerlink" title="3.4.2.5 修改服务器hosts文件"></a>3.4.2.5 修改服务器hosts文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop001 ~]# vim /etc/hosts</span><br><span class="line">127.0.0.1 localhost  localhost</span><br><span class="line">::1     localhost       localhost.localdomain   localhost6      localhost6.localdomain6</span><br><span class="line">172.17.138.24 hadoop001 hadoop1</span><br><span class="line">172.17.138.25 hadoop002 hadoop2</span><br><span class="line">172.17.138.23 hadoop003 hadoop3</span><br></pre></td></tr></table></figure>

<p>注意：这里每个人不一样，ip填写的是私有ip，做完后ping一下。</p>
<h3 id="3-4-3-编写集群分发脚本xsync"><a href="#3-4-3-编写集群分发脚本xsync" class="headerlink" title="3.4.3 编写集群分发脚本xsync"></a>3.4.3 编写集群分发脚本xsync</h3><p>1）xsync集群分发脚本</p>
<p>（1）需求：循环复制文件到所有节点的相同目录下</p>
<p>​    （2）需求分析</p>
<ol>
<li>rsync命令原始拷贝：</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync  -av     /opt/module  		 root@hadoop103:/opt/</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>期望脚本：</li>
</ol>
<p>xsync要同步的文件名称</p>
<ol start="3">
<li>说明：在/home/atguigu/bin这个目录下存放的脚本，atguigu用户可以在系统任何地方直接执行。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ echo $PATH</span><br><span class="line">/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/atguigu/.local/bin:/home/atguigu/bin</span><br></pre></td></tr></table></figure>

<p>（3）脚本实现</p>
<ol>
<li>在用的家目录/home/atguigu下创建bin文件夹</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ mkdir bin</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>在/home/atguigu/bin目录下创建xsync文件，以便全局调用</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd /home/atguigu/bin</span><br><span class="line">[atguigu@hadoop102 ~]$ vim xsync</span><br></pre></td></tr></table></figure>

<p>在该文件中编写如下代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line"><span class="meta">  #</span><span class="bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host "mkdir -p $pdir"</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>修改脚本xsync具有执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 xsync</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ xsync xsync</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="3-4-4-SSH无密登录配置"><a href="#3-4-4-SSH无密登录配置" class="headerlink" title="3.4.4 SSH无密登录配置"></a>3.4.4 SSH无密登录配置</h3><p>说明：这里面只配置了hadoop102、hadoop103到其他主机的无密登录；因为hadoop102配置的是NameNode，hadoop103配置的是ResourceManager，都要求对其他节点无密访问。</p>
<p>（1）hadoop102上生成公钥和私钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）。</p>
<p>（2）将hadoop102公钥拷贝到要免密登录的目标机器上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure>

<p>（3）hadoop103上生成公钥和私钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）。</p>
<p>（4）将hadoop103公钥拷贝到要免密登录的目标机器上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure>

<h3 id="3-4-5-JDK准备"><a href="#3-4-5-JDK准备" class="headerlink" title="3.4.5 JDK准备"></a>3.4.5 JDK准备</h3><p>1）卸载现有JDK（3台节点）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop103 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop104 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<p>（1）rpm -qa：表示查询所有已经安装的软件包</p>
<p>（2）grep -i：表示过滤时不区分大小写</p>
<p>（3）xargs -n1：表示一次获取上次执行结果的一个值</p>
<p>（4）rpm -e –nodeps：表示卸载软件</p>
<p>2）用XShell工具将JDK导入到hadoop102的/opt/software文件夹下面</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps51.jpg" alt="img"> </p>
<p>3）在Linux系统下的opt目录中查看软件包是否导入成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]# ls /opt/software/</span><br></pre></td></tr></table></figure>

<p>看到如下结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdk-8u212-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>

<p>4）解压JDK到/opt/module目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]# tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br><span class="line">[atguigu@hadoop102 module]$ mv jdk1.8.0_212/ jdk-1.8.0</span><br></pre></td></tr></table></figure>

<p>5）配置JDK环境变量</p>
<p>（1）新建/etc/profile.d/my_env.sh文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]# sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>添加如下内容，然后保存（:wq）退出。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk-1.8.0</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<p>（2）让环境变量生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>6）测试JDK是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]# java -version</span><br></pre></td></tr></table></figure>

<p>如果能看到以下结果、则Java正常安装。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java version "1.8.0_212"</span><br></pre></td></tr></table></figure>

<p>7）分发JDK </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ xsync /opt/module/jdk-1.8.0</span><br></pre></td></tr></table></figure>

<p>8）分发环境变量配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ sudo /home/atguigu/bin/xsync /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>9）分别在hadoop103、hadoop104上执行source</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 module]$ source /etc/profile.d/my_env.sh</span><br><span class="line">[atguigu@hadoop104 module]$ source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<h3 id="3-4-6-环境变量配置说明"><a href="#3-4-6-环境变量配置说明" class="headerlink" title="3.4.6 环境变量配置说明"></a>3.4.6 环境变量配置说明</h3><p>Linux的环境变量可在多个文件中配置，如/etc/profile，/etc/profile.d/.sh，<del>/.bashrc，</del>/.bash_profile等，下面说明上述几个文件之间的关系和区别。</p>
<p>bash的运行模式可分为login shell和non-login shell。</p>
<p>例如，我们通过终端，输入用户名、密码，登录系统之后，得到就是一个login shell。而当我们执行以下命令ssh hadoop103 command，在hadoop103执行command的就是一个non-login shell。</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps52.png" alt="img"> </p>
<p>这两种shell的主要区别在于，它们启动时会加载不同的配置文件，login shell启动时会加载/etc/profile，<del>/.bash_profile，</del>/.bashrc。non-login shell启动时会加载~/.bashrc。</p>
<p>而在加载<del>/.bashrc（实际是</del>/.bashrc中加载的/etc/bashrc）或/etc/profile时，都会执行如下代码片段，</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps53.jpg" alt="img"> </p>
<p>因此不管是login shell还是non-login shell，启动时都会加载/etc/profile.d/.sh中的环境变量。</p>
<h2 id="3-5-数据模拟"><a href="#3-5-数据模拟" class="headerlink" title="3.5 数据模拟"></a>3.5 数据模拟</h2><h3 id="3-5-1-使用说明"><a href="#3-5-1-使用说明" class="headerlink" title="3.5.1 使用说明"></a>3.5.1 使用说明</h3><p>1）将application.yml、gmall-remake-mock-2023-02-17.jar、path.json、logback.xml上传到hadoop102的/opt/module/applog目录下</p>
<p>（1）创建applog路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ mkdir /opt/module/applog</span><br></pre></td></tr></table></figure>

<p>（2）上传文件到/opt/module/applog目录</p>
<p>2）配置文件</p>
<p>（1）application.yml文件</p>
<p>可以根据需求生成对应日期的用户行为日志。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 applog]$ vim application.yml</span><br></pre></td></tr></table></figure>

<p>修改如下内容</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 外部配置打开</span></span><br><span class="line"><span class="attr">logging.config:</span> <span class="string">./logback.xml</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#http模式下，发送的地址</span></span><br><span class="line"><span class="attr">mock:</span></span><br><span class="line">  <span class="attr">log:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">"file"</span>      <span class="comment">#"file" "http" "kafka" "none"</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">"http://localhost:8090/applog"</span></span><br><span class="line">    <span class="attr">kafka:</span></span><br><span class="line">        <span class="attr">server:</span> <span class="string">"hadoop102:9092,hadoop102:9092,hadoop102:9092"</span></span><br><span class="line">        <span class="attr">topic:</span> <span class="string">"topic_log"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">datasource:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">com.alibaba.druid.pool.DruidDataSource</span></span><br><span class="line">      <span class="attr">druid:</span></span><br><span class="line">        <span class="attr">url:</span> <span class="string">jdbc:mysql://hadoop102:3306/gmall?characterEncoding=utf-8&amp;allowPublicKeyRetrieval=true&amp;useSSL=false&amp;serverTimezone=GMT%2B8</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">root</span></span><br><span class="line">        <span class="attr">password:</span> <span class="string">"000000"</span></span><br><span class="line">        <span class="attr">driver-class-name:</span>  <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">        <span class="attr">max-active:</span> <span class="number">20</span></span><br><span class="line">        <span class="attr">test-on-borrow:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">mybatis-plus.global-config.db-config.field-strategy:</span> <span class="string">not_null</span></span><br><span class="line"><span class="attr">mybatis-plus:</span></span><br><span class="line">  <span class="attr">mapper-locations:</span> <span class="string">classpath:mapper/.xml</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mybatis:</span></span><br><span class="line">   <span class="attr">mapper-locations:</span> <span class="string">classpath:mapper/.xml</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#业务日期， 并非Linux系统时间的日期，而是生成模拟数据的日期</span></span><br><span class="line"><span class="attr">mock.date:</span> <span class="string">"2022-06-08"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志是否写入数据库一份  写入z_log表中</span></span><br><span class="line"><span class="attr">mock.log.db.enable:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清空</span></span><br><span class="line"><span class="attr">mock.clear.busi:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清空用户</span></span><br><span class="line"><span class="attr">mock.clear.user:</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量生成新用户</span></span><br><span class="line"><span class="attr">mock.new.user:</span> <span class="number">0</span></span><br><span class="line">  <span class="comment">#session次数</span></span><br><span class="line"><span class="attr">mock.user-session.count:</span> <span class="number">200</span></span><br><span class="line">  <span class="comment">#设备最大值</span></span><br><span class="line"><span class="attr">mock.max.mid:</span> <span class="number">1000000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否针对实时生成数据，若启用（置为1）则数据的 yyyy-MM-dd 与 mock.date 一致而 HH:mm:ss 与系统时间一致；若禁用则数据的 yyyy-MM-dd 与 mock.date 一致而 HH:mm:ss 随机分布，此处禁用</span></span><br><span class="line"><span class="attr">mock.if-realtime:</span> <span class="number">0</span></span><br><span class="line"><span class="comment">#访问时间分布权重</span></span><br><span class="line"><span class="attr">mock.start-time-weight:</span> <span class="string">"10:5:0:0:0:0:5:5:5:10:10:15:20:10:10:10:10:10:20:25:30:35:30:20"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#支付类型占比 支付宝 ：微信 :银联</span></span><br><span class="line"><span class="attr">mock.payment_type_weight:</span> <span class="string">"40:50:10"</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#页面平均访问时间</span></span><br><span class="line"><span class="attr">mock.page.during-time-ms:</span> <span class="number">20000</span></span><br><span class="line">  <span class="comment">#错误概率 百分比</span></span><br><span class="line"><span class="attr">mock.error.rate:</span> <span class="number">3</span></span><br><span class="line">  <span class="comment">#每条日志发送延迟 ms</span></span><br><span class="line"><span class="attr">mock.log.sleep:</span> <span class="number">100</span></span><br><span class="line">  <span class="comment">#课程详情来源  用户查询，商品推广，智能推荐, 促销活动</span></span><br><span class="line"><span class="attr">mock.detail.source-type-rate:</span> <span class="string">"40:25:15:20"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mock.if-cart-rate:</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mock.if-favor-rate:</span> <span class="number">70</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mock.if-order-rate:</span> <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mock.if-refund-rate:</span> <span class="number">50</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">#搜索关键词</span></span><br><span class="line"><span class="attr">mock.search.keyword:</span> <span class="string">"java,python,多线程,前端,数据库,大数据,hadoop,flink"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">#用户数据变化概率</span></span><br><span class="line"><span class="attr">mock.user.update-rate:</span> <span class="number">20</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 男女浏览品牌比重（11 品牌)</span></span><br><span class="line"><span class="attr">mock.tm-weight.male:</span> <span class="string">"3:2:5:5:5:1:1:1:1:1:1"</span></span><br><span class="line"><span class="attr">mock.tm-weight.female:</span> <span class="string">"1:5:1:1:2:2:2:5:5:5:5"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 外连类型比重（5 种）</span></span><br><span class="line"><span class="attr">mock.refer-weight:</span> <span class="string">"10:2:3:4:5"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 线程池相关配置</span></span><br><span class="line"><span class="attr">mock.pool.core:</span> <span class="number">20</span></span><br><span class="line"><span class="attr">mock.pool.max-core:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure>

<p>（2）path.json，该文件用来配置访问路径</p>
<p>根据需求，可以灵活配置用户点击路径。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;"path":["start_app","home", "search", "good_list","good_detail","good_detail" ,"good_detail","cart","order","payment","mine","order_list","end"],"rate":100 &#125;,</span><br><span class="line">  &#123;"path":["start_app","home", "good_list","good_detail","good_detail" ,"good_detail","cart","end"],"rate":30 &#125;,</span><br><span class="line">  &#123;"path":["start_app","home", "activity1111","good_detail"  ,"cart","good_detail","cart","order","payment","end"],"rate":30 &#125;,</span><br><span class="line">  &#123;"path":[ "activity1111","good_detail" ,"activity1111" ,"good_detail","order","payment","end"],"rate":200 &#125;,</span><br><span class="line">  &#123;"path":[ "start_app","home" ,"activity1111" ,"good_detail","order","payment","end"],"rate":200 &#125;,</span><br><span class="line">  &#123;"path":[ "start_app","home" , "good_detail","order","payment","end"],"rate":30 &#125;,</span><br><span class="line">  &#123;"path":[  "good_detail","order","payment","end"],"rate":650 &#125;,</span><br><span class="line">  &#123;"path":[  "good_detail"  ],"rate":30 &#125;,</span><br><span class="line">  &#123;"path":[  "start_app","home","mine","good_detail"  ],"rate":30 &#125;,</span><br><span class="line">  &#123;"path":[  "start_app","home", "good_detail","good_detail","good_detail","cart","order","payment","end"  ],"rate":200 &#125;,</span><br><span class="line">  &#123;"path":[  "start_app","home", "search","good_list","good_detail","cart","order","payment","end"  ],"rate":200 &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>（3）logback配置文件</p>
<p>可配置日志生成路径，修改内容如下。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_HOME"</span> <span class="attr">value</span>=<span class="string">"/opt/module/applog/log"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"console"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.out<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"console_em"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>System.err<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"rollingFile"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$&#123;LOG_HOME&#125;/app.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>$&#123;LOG_HOME&#125;/app.%d&#123;yyyy-MM-dd&#125;.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 将某一个包下日志单独打印日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.atguigu.mock.util.LogUtil"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">level</span>=<span class="string">"INFO"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"rollingFile"</span> /&gt;</span></span><br><span class="line"><span class="comment">&lt;!--           &lt;appender-ref ref="console" /&gt;--&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"com.atguigu.gmallre.mock.task.UserMockTask"</span> <span class="attr">level</span>=<span class="string">"INFO"</span> <span class="attr">additivity</span>=<span class="string">"false"</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"console_em"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--    &lt;logger name="com.alibaba.druid.pool" level="error" additivity="false" &gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--        &lt;appender-ref ref="console" /&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--    &lt;/logger&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--    &lt;logger  name="com.atguigu.edu2021.mock.mapper" level="debug"&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--         &lt;appender-ref ref="console" /&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--    &lt;/logger&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--      &lt;logger  name="com.atguigu.edu2021.mock.service.impl.UserInfoServiceImpl" level="debug"&gt;</span></span><br><span class="line"><span class="comment">             &lt;appender-ref ref="console" /&gt;</span></span><br><span class="line"><span class="comment">       &lt;/logger&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"error"</span>  &gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"console_em"</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;appender-ref ref="async-rollingFile" /&gt;  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>3）生成日志</p>
<p>（1）进入到/opt/module/applog路径，执行以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 applog]$ java -jar gmall-remake-mock-2023-02-17.jar test 100 2022-06-08</span><br></pre></td></tr></table></figure>

<ol>
<li><p>增加test参数为测试模式，只生成用户行为数据不生成业务数据。</p>
</li>
<li><p>100 为产生的用户session数一个session默认产生1条启动日志和5条页面方法日志。</p>
</li>
<li><p>第三个参数为日志数据的日期，测试模式下不会加载配置文件，要指定数据日期只能通过命令行传参实现。</p>
</li>
<li><p>三个参数的顺序必须与示例保持一致</p>
</li>
<li><p>第二个参数和第三个参数可以省略，如果test后面不填写参数，默认为1000</p>
</li>
</ol>
<p>（2）在/opt/module/applog/log目录下查看生成日志</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 log]$ ll</span><br></pre></td></tr></table></figure>

<h3 id="3-5-2-集群日志生成脚本"><a href="#3-5-2-集群日志生成脚本" class="headerlink" title="3.5.2 集群日志生成脚本"></a>3.5.2 集群日志生成脚本</h3><p>（1）在/home/atguigu/bin目录下创建脚本lg.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ vim lg.sh</span><br></pre></td></tr></table></figure>

<p>（2）在脚本中编写如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">echo "========== hadoop102 =========="</span><br><span class="line">ssh hadoop102 "cd /opt/module/applog/; nohup java -jar gmall-remake-mock-2023-02-17.jar $1 $2 $3 &gt;/dev/null 2&gt;&amp;1 &amp;"</span><br></pre></td></tr></table></figure>

<p>done注：</p>
<ol>
<li><p>/opt/module/applog/为jar包及配置文件所在路径</p>
</li>
<li><p>/dev/null代表Linux的空设备文件，所有往这个文件里面写入的内容都会丢失，俗称“黑洞”。</p>
</li>
</ol>
<p>标准输入0：从键盘获得输入 /proc/self/fd/0 </p>
<p>标准输出1：输出到屏幕（即控制台） /proc/self/fd/1 </p>
<p>错误输出2：输出到屏幕（即控制台） /proc/self/fd/2</p>
<p>（3）修改脚本执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 lg.sh</span><br></pre></td></tr></table></figure>

<p>（4）将jar包及配置文件上传至hadoop103的/opt/module/applog/路径</p>
<p>（5）启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ lg.sh test 100</span><br></pre></td></tr></table></figure>

<p>（6）分别在hadoop102、hadoop103的/opt/module/applog/log目录上查看生成的数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 log]$ ls</span><br><span class="line">app.log</span><br></pre></td></tr></table></figure>

<h1 id="第4章-用户行为数据采集模块"><a href="#第4章-用户行为数据采集模块" class="headerlink" title="第4章 用户行为数据采集模块"></a>第4章 用户行为数据采集模块</h1><h2 id="4-1-数据通道"><a href="#4-1-数据通道" class="headerlink" title="4.1 数据通道"></a>4.1 数据通道</h2><p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1-1723016319645-1.png" alt="img"></p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/image-20240809144458845.png" alt="image-20240809144458845"></p>
<h2 id="4-2-环境准备"><a href="#4-2-环境准备" class="headerlink" title="4.2 环境准备"></a>4.2 环境准备</h2><h3 id="4-2-1-集群命令批量执行脚本"><a href="#4-2-1-集群命令批量执行脚本" class="headerlink" title="4.2.1 集群命令批量执行脚本"></a>4.2.1 集群命令批量执行脚本</h3><p>1）在/home/atguigu/bin目录下创建脚本xcall</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ vim xcall</span><br></pre></td></tr></table></figure>

<p>2）在脚本中编写如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">! /bin/bash</span></span><br><span class="line"> </span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo --------- $i ----------</span><br><span class="line">    ssh $i "$"</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>3）修改脚本执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 xcall</span><br></pre></td></tr></table></figure>

<p>4）启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ xcall jps</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-Hadoop安装"><a href="#4-2-2-Hadoop安装" class="headerlink" title="4.2.2 Hadoop安装"></a>4.2.2 Hadoop安装</h3><h4 id="4-2-2-1-安装步骤"><a href="#4-2-2-1-安装步骤" class="headerlink" title="4.2.2.1 安装步骤"></a>4.2.2.1 安装步骤</h4><p>完全分布式运行模式（开发重点）</p>
<p>分析：</p>
<p>​    1）准备3台客户机（关闭防火墙、静态IP、主机名称）</p>
<p>​    2）安装JDK</p>
<p>​    3）配置环境变量</p>
<p>​    4）安装Hadoop</p>
<p>​    5）配置环境变量</p>
<p>​    6）配置集群</p>
<p>​    7）单点启动</p>
<p>​    8）配置ssh</p>
<p>​    9）群起并测试集群</p>
<h5 id="4-2-2-1-1-Hadoop部署"><a href="#4-2-2-1-1-Hadoop部署" class="headerlink" title="4.2.2.1.1 Hadoop部署"></a>4.2.2.1.1 Hadoop部署</h5><p>1）集群部署规划</p>
<p>​    注意：NameNode和SecondaryNameNode不要安装在同一台服务器</p>
<p>​    注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p>
<table>
<thead>
<tr>
<th></th>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNodeDataNode</td>
<td>DataNode</td>
<td>SecondaryNameNodeDataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>ResourceManagerNodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<p>2）用SecureCRT工具将hadoop3.3.4.tar.gz导入到opt目录下面的software文件夹下面</p>
<p>切换到sftp连接页面，选择Linux下编译的hadoop jar包拖入，如图2-32所示</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps1-1723016397748-3.jpg" alt="img"> </p>
<p>图 拖入hadoop的tar包</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps2-1723016397748-4.jpg" alt="img"> </p>
<p>图2-33 拖入Hadoop的tar包成功</p>
<p>3）进入到Hadoop安装包路径下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd /opt/software/</span><br></pre></td></tr></table></figure>

<p>4）解压安装文件到/opt/module下面</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf hadoop-3.3.4.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>5）查看是否解压成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ ls /opt/module/hadoop-3.3.4</span><br></pre></td></tr></table></figure>

<p>6）重命名</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ mv /opt/module/hadoop-3.3.4 /opt/module/hadoop</span><br></pre></td></tr></table></figure>

<p>7）将Hadoop添加到环境变量</p>
<p>​    （1）获取Hadoop安装路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ pwd</span><br><span class="line">/opt/module/hadoop</span><br></pre></td></tr></table></figure>

<p>​    （2）打开/etc/profile.d/my_env.sh文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>在profile文件末尾添加JDK路径：（shitf+g）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>（3）保存后退出</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:wq</span><br></pre></td></tr></table></figure>

<p>（4）分发环境变量文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ sudo /home/atguigu/bin/xsync /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>（5）source 是之生效（3台节点）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ source /etc/profile.d/my_env.sh</span><br><span class="line">[atguigu@hadoop103 module]$ source /etc/profile.d/my_env.sh</span><br><span class="line">[atguigu@hadoop104 module]$ source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<h5 id="4-2-2-1-2-配置集群"><a href="#4-2-2-1-2-配置集群" class="headerlink" title="4.2.2.1.2 配置集群"></a>4.2.2.1.2 配置集群</h5><p>1）核心配置文件</p>
<p>配置core-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd $HADOOP_HOME/etc/hadoop</span><br><span class="line">[atguigu@hadoop102 hadoop]$ vim core-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>2）HDFS配置文件</p>
<p>配置hdfs-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;!-- nn web端访问地址--&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop102:9870&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">	&lt;!-- 2nn web端访问地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop104:9868&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;!-- 测试环境指定HDFS副本的数量1 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>3）YARN配置文件</p>
<p>配置yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--yarn单个容器允许分配的最大最小内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- yarn容器允许管理的物理内存大小 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>4）MapReduce配置文件</p>
<p>配置mapred-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>5）配置workers</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim /opt/module/hadoop/etc/hadoop/workers</span><br></pre></td></tr></table></figure>

<p>在该文件中增加如下内容：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hadoop102</span></span><br><span class="line"><span class="attr">hadoop103</span></span><br><span class="line"><span class="attr">hadoop104</span></span><br></pre></td></tr></table></figure>

<p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p>
<h5 id="4-2-2-1-3-配置历史服务器"><a href="#4-2-2-1-3-配置历史服务器" class="headerlink" title="4.2.2.1.3 配置历史服务器"></a>4.2.2.1.3 配置历史服务器</h5><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p>
<p>1）配置mapred-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="4-2-2-1-4-配置日志的聚集"><a href="#4-2-2-1-4-配置日志的聚集" class="headerlink" title="4.2.2.1.4 配置日志的聚集"></a>4.2.2.1.4 配置日志的聚集</h5><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。</p>
<p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p>
<p>注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。</p>
<p>开启日志聚集功能具体步骤如下：</p>
<p>1）配置yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="4-2-2-1-5-分发Hadoop"><a href="#4-2-2-1-5-分发Hadoop" class="headerlink" title="4.2.2.1.5 分发Hadoop"></a>4.2.2.1.5 分发Hadoop</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop/</span><br></pre></td></tr></table></figure>

<h5 id="4-2-2-1-6-群起集群"><a href="#4-2-2-1-6-群起集群" class="headerlink" title="4.2.2.1.6 群起集群"></a>4.2.2.1.6 群起集群</h5><p>1）启动集群</p>
<p>​    （1）如果集群是第一次启动，需要在hadoop102节点格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ cd /opt/module/hadoop/</span><br><span class="line">[atguigu@hadoop102 hadoop]$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>

<p>（2）启动HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>

<p>（3）在配置了ResourceManager的节点（hadoop103）启动YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>（4）Web端查看HDFS的Web页面：<a href="http://hadoop102:9870/" target="_blank" rel="noopener">http://hadoop102:9870/</a></p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps3.jpg" alt="img"> </p>
<p>（5）Web端查看SecondaryNameNode</p>
<p>① 浏览器中输入：<a href="http://hadoop104:9868/status.html" target="_blank" rel="noopener">http://hadoop104:9868/status.html</a></p>
<p>​    ② 查看SecondaryNameNode信息</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps4.jpg" alt="img"> </p>
<h5 id="4-2-2-1-7-Hadoop群起脚本"><a href="#4-2-2-1-7-Hadoop群起脚本" class="headerlink" title="4.2.2.1.7 Hadoop群起脚本"></a>4.2.2.1.7 Hadoop群起脚本</h5><p>（1）在/home/atguigu/bin目录下创建hdp.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ cd /home/atguigu/bin</span><br><span class="line">[atguigu@hadoop102 bin]$ vim hdp.sh</span><br></pre></td></tr></table></figure>

<p>（2）写入以下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo "No Args Input..."</span><br><span class="line">    exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">"start")</span><br><span class="line">        echo " =================== 启动 hadoop集群 ==================="</span><br><span class="line"></span><br><span class="line">        echo " --------------- 启动 hdfs ---------------"</span><br><span class="line">        ssh hadoop102 "/opt/module/hadoop/sbin/start-dfs.sh"</span><br><span class="line">        echo " --------------- 启动 yarn ---------------"</span><br><span class="line">        ssh hadoop103 "/opt/module/hadoop/sbin/start-yarn.sh"</span><br><span class="line">        echo " --------------- 启动 historyserver ---------------"</span><br><span class="line">        ssh hadoop102 "/opt/module/hadoop/bin/mapred --daemon start historyserver"</span><br><span class="line">;;</span><br><span class="line">"stop")</span><br><span class="line">        echo " =================== 关闭 hadoop集群 ==================="</span><br><span class="line"></span><br><span class="line">        echo " --------------- 关闭 historyserver ---------------"</span><br><span class="line">        ssh hadoop102 "/opt/module/hadoop/bin/mapred --daemon stop historyserver"</span><br><span class="line">        echo " --------------- 关闭 yarn ---------------"</span><br><span class="line">        ssh hadoop103 "/opt/module/hadoop/sbin/stop-yarn.sh"</span><br><span class="line">        echo " --------------- 关闭 hdfs ---------------"</span><br><span class="line">        ssh hadoop102 "/opt/module/hadoop/sbin/stop-dfs.sh"</span><br><span class="line">;;</span><br><span class="line">)</span><br><span class="line">    echo "Input Args Error..."</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>（3）增加权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 hdp.sh</span><br></pre></td></tr></table></figure>

<p>（4）启动集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ hdp.sh start</span><br></pre></td></tr></table></figure>

<p>日志如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">=================== 启动 hadoop集群 ===================</span><br><span class="line"> --------------- 启动 hdfs ---------------</span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br><span class="line"> --------------- 启动 yarn ---------------</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br><span class="line"> --------------- 启动 historyserver ---------------</span><br></pre></td></tr></table></figure>

<p>查看进程。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ xcall jps</span><br></pre></td></tr></table></figure>

<p>结果如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--------- hadoop102 ----------</span><br><span class="line">3074 Jps</span><br><span class="line">2116 NameNode</span><br><span class="line">2245 DataNode</span><br><span class="line">2761 JobHistoryServer</span><br><span class="line">2590 NodeManager</span><br><span class="line">--------- hadoop103 ----------</span><br><span class="line">3270 NodeManager</span><br><span class="line">2952 DataNode</span><br><span class="line">3148 ResourceManager</span><br><span class="line">3854 Jps</span><br><span class="line">--------- hadoop104 ----------</span><br><span class="line">1889 DataNode</span><br><span class="line">2100 NodeManager</span><br><span class="line">2446 Jps</span><br><span class="line">1967 SecondaryNameNode</span><br></pre></td></tr></table></figure>

<p>（5）停止集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ hdp.sh stop</span><br></pre></td></tr></table></figure>

<p>日志如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">=================== 关闭 hadoop集群 ===================</span><br><span class="line"> --------------- 关闭 historyserver ---------------</span><br><span class="line"> --------------- 关闭 yarn ---------------</span><br><span class="line">Stopping nodemanagers</span><br><span class="line">Stopping resourcemanager</span><br><span class="line"> --------------- 关闭 hdfs ---------------</span><br><span class="line">Stopping namenodes on [hadoop102]</span><br><span class="line">Stopping datanodes</span><br><span class="line">Stopping secondary namenodes [hadoop104]</span><br></pre></td></tr></table></figure>

<p>查看进程。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ xcall jps</span><br></pre></td></tr></table></figure>

<p>结果如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--------- hadoop102 ----------</span><br><span class="line">3691 Jps</span><br><span class="line">--------- hadoop103 ----------</span><br><span class="line">4221 Jps</span><br><span class="line">--------- hadoop104 ----------</span><br><span class="line">2647 Jps</span><br></pre></td></tr></table></figure>

<h4 id="4-2-2-2-项目经验"><a href="#4-2-2-2-项目经验" class="headerlink" title="4.2.2.2 项目经验"></a>4.2.2.2 项目经验</h4><p>（1）项目经验之HDFS存储多目录</p>
<ol>
<li>生产环境服务器磁盘情况</li>
</ol>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps7-1723017610125-9.jpg" alt="img"> </p>
<ol start="2">
<li>在hdfs-site.xml文件中配置多目录，注意新挂载磁盘的访问权限问题。</li>
</ol>
<p>HDFS的DataNode节点保存数据的路径由dfs.datanode.data.dir参数决定，其默认值为file://${hadoop.tmp.dir}/dfs/data，若服务器有多个磁盘，必须对该参数进行修改。如服务器磁盘如上图所示，则该参数应修改为如下的值。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>注意：每台服务器挂载的磁盘不一样，所以每个节点的多目录配置可以不一致。单独配置即可。</p>
<p>（2）项目经验之集群数据均衡</p>
<ol>
<li>节点间数据均衡</li>
</ol>
<p>开启数据均衡命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-balancer.sh -threshold 10</span><br></pre></td></tr></table></figure>

<p>对于参数10，代表的是集群中各个节点的磁盘空间利用率相差不超过10%，可根据实际情况进行调整。</p>
<p>停止数据均衡命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-balancer.sh</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>磁盘间数据均衡</li>
</ol>
<p>生成均衡计划（我们只有一块磁盘，不会生成计划）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -plan hadoop103</span><br></pre></td></tr></table></figure>

<p>执行均衡计划。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -execute hadoop103.plan.json</span><br></pre></td></tr></table></figure>

<p>查看当前均衡任务的执行情况。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -query hadoop103</span><br></pre></td></tr></table></figure>

<p>取消均衡任务。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs diskbalancer -cancel hadoop103.plan.json</span><br></pre></td></tr></table></figure>

<p>（3）项目经验之Hadoop参数调优</p>
<ol>
<li>HDFS参数调优hdfs-site.xml</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">The number of Namenode RPC server threads that listen to requests from clients. If dfs.namenode.servicerpc-address is not configured then Namenode RPC server threads listen to requests from all nodes.</span><br><span class="line">NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。</span><br><span class="line">对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;10&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>dfs.namenode.handler.count=<img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps8-1723017610125-10.jpg" alt="img">，比如集群规模为8台时，此参数设置为41。可通过简单的python代码计算该值，代码如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ python</span><br><span class="line">Python 2.7.5 (default, Apr 11 2018, 07:36:10) </span><br><span class="line">[GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linux2</span><br><span class="line">Type "help", "copyright", "credits" or "license" for more information.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; import math</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; <span class="built_in">print</span> int(20math.log(8))</span></span><br><span class="line">41</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; quit()</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>YARN参数调优yarn-site.xml</li>
</ol>
<p>情景描述：总共7台机器，每天几亿条数据，数据源-&gt;Flume-&gt;Kafka-&gt;HDFS-&gt;Hive</p>
<p>面临问题：数据统计主要用HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启的JVM重用，而且IO没有阻塞，内存用了不到50%。但是还是跑的非常慢，而且数据量洪峰过来时，整个集群都会宕掉。基于这种情况有没有优化方案。</p>
<p>解决办法：</p>
<p>内存利用率不够。这个一般是Yarn的2个配置造成的，单个任务可以申请的最大内存大小，和Hadoop单个节点可用内存大小。调节这两个参数能提高系统内存的利用率。</p>
<p>（a）yarn.nodemanager.resource.memory-mb</p>
<p>表示该节点上YARN可使用的物理内存总量，默认是8192（MB），注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。</p>
<p>（b）yarn.scheduler.maximum-allocation-mb</p>
<p>单个任务可申请的最多物理内存量，默认是8192（MB）。</p>
<h3 id="4-2-3-Zookeeper安装"><a href="#4-2-3-Zookeeper安装" class="headerlink" title="4.2.3 Zookeeper安装"></a>4.2.3 Zookeeper安装</h3><h4 id="4-2-3-1-分布式安装部署"><a href="#4-2-3-1-分布式安装部署" class="headerlink" title="4.2.3.1 分布式安装部署"></a>4.2.3.1 分布式安装部署</h4><p>1）集群规划</p>
<p>在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper。</p>
<table>
<thead>
<tr>
<th></th>
<th>服务器hadoop102</th>
<th>服务器hadoop103</th>
<th>服务器hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
</tr>
</tbody></table>
<p>2）解压安装</p>
<p>（1）解压Zookeeper安装包到/opt/module/目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf apache-zookeeper-3.7.1-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>（2）修改/opt/module/apache-zookeeper-3.7.1-bin名称为zookeeper-3.7.1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ mv apache-zookeeper-3.7.1-bin/ zookeeper</span><br></pre></td></tr></table></figure>

<p>3）配置服务器编号</p>
<p>（1）在/opt/module/zookeeper/目录下创建zkData</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 zookeeper]$ mkdir zkData</span><br></pre></td></tr></table></figure>

<p>（2）在/opt/module/zookeeper/zkData目录下创建一个myid的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 zkData]$ vim myid</span><br></pre></td></tr></table></figure>

<p>添加myid文件，注意一定要在linux里面创建，在notepad++里面很可能乱码</p>
<p>在文件中添加与server对应的编号：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2</span><br></pre></td></tr></table></figure>

<p>4）配置zoo.cfg文件</p>
<p>（1）重命名/opt/module/zookeeper/conf目录下的zoo_sample.cfg为zoo.cfg</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 conf]$ mv zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure>

<p>（2）打开zoo.cfg文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 conf]$ vim zoo.cfg</span><br></pre></td></tr></table></figure>

<p>修改数据存储路径配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/opt/module/zookeeper/zkData</span><br></pre></td></tr></table></figure>

<p>增加如下配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">######################cluster##########################</span></span></span><br><span class="line">server.2=hadoop102:2888:3888</span><br><span class="line">server.3=hadoop103:2888:3888</span><br><span class="line">server.4=hadoop104:2888:3888</span><br></pre></td></tr></table></figure>

<p>（3）同步/opt/module/zookeeper目录内容到hadoop103、hadoop104</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ xsync zookeeper/</span><br></pre></td></tr></table></figure>

<p>（4）分别修改hadoop103、hadoop104上的myid文件中内容为3、4</p>
<p>（5）zoo.cfg配置参数解读</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.A=B:C:D。</span><br></pre></td></tr></table></figure>

<p>A是一个数字，表示这个是第几号服务器；</p>
<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
<p>B是这个服务器的地址；</p>
<p>C是这个服务器Follower与集群中的Leader服务器交换信息的端口；</p>
<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
<p>5）集群操作</p>
<p>（1）分别启动Zookeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 zookeeper]$ bin/zkServer.sh start</span><br><span class="line">[atguigu@hadoop103 zookeeper]$ bin/zkServer.sh start</span><br><span class="line">[atguigu@hadoop104 zookeeper]$ bin/zkServer.sh start</span><br></pre></td></tr></table></figure>

<p>（2）查看状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 zookeeper]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line">[atguigu@hadoop103 zookeeper]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line">[atguigu@hadoop104 zookeeper]# bin/zkServer.sh status</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>

<h4 id="4-2-3-2-ZK集群启动停止脚本"><a href="#4-2-3-2-ZK集群启动停止脚本" class="headerlink" title="4.2.3.2 ZK集群启动停止脚本"></a>4.2.3.2 ZK集群启动停止脚本</h4><p>1）在hadoop102的/home/atguigu/bin目录下创建脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ vim zk.sh</span><br></pre></td></tr></table></figure>

<p>​    在脚本中编写如下内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">"start")&#123;</span><br><span class="line">	for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">	do</span><br><span class="line">        echo ---------- zookeeper $i 启动 ------------</span><br><span class="line">		ssh $i "/opt/module/zookeeper/bin/zkServer.sh start"</span><br><span class="line">	done</span><br><span class="line">&#125;;;</span><br><span class="line">"stop")&#123;</span><br><span class="line">	for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">	do</span><br><span class="line">        echo ---------- zookeeper $i 停止 ------------    </span><br><span class="line">		ssh $i "/opt/module/zookeeper/bin/zkServer.sh stop"</span><br><span class="line">	done</span><br><span class="line">&#125;;;</span><br><span class="line">"status")&#123;</span><br><span class="line">	for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">	do</span><br><span class="line">        echo ---------- zookeeper $i 状态 ------------    </span><br><span class="line">		ssh $i "/opt/module/zookeeper/bin/zkServer.sh status"</span><br><span class="line">	done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>2）增加脚本执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 zk.sh</span><br></pre></td></tr></table></figure>

<p>3）Zookeeper集群启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ zk.sh start</span><br></pre></td></tr></table></figure>

<p>4）Zookeeper集群停止脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ zk.sh stop</span><br></pre></td></tr></table></figure>

<h4 id="4-2-3-3-客户端命令行操作"><a href="#4-2-3-3-客户端命令行操作" class="headerlink" title="4.2.3.3 客户端命令行操作"></a>4.2.3.3 客户端命令行操作</h4><table>
<thead>
<tr>
<th>命令基本语法</th>
<th>功能描述</th>
</tr>
</thead>
<tbody><tr>
<td>help</td>
<td>显示所有操作命令</td>
</tr>
<tr>
<td>ls path</td>
<td>使用 ls 命令来查看当前znode的子节点-w 监听子节点变化-s  附加次级信息</td>
</tr>
<tr>
<td>create</td>
<td>普通创建-s  含有序列-e  临时（重启或者超时消失）</td>
</tr>
<tr>
<td>get path</td>
<td>获得节点的值-w 监听节点内容变化-s  附加次级信息</td>
</tr>
<tr>
<td>set</td>
<td>设置节点的具体值</td>
</tr>
<tr>
<td>stat</td>
<td>查看节点状态</td>
</tr>
<tr>
<td>delete</td>
<td>删除节点</td>
</tr>
<tr>
<td>deleteall</td>
<td>递归删除节点</td>
</tr>
</tbody></table>
<p>1）启动客户端</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 zookeeper]$ bin/zkCli.sh</span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-Kafka安装"><a href="#4-2-4-Kafka安装" class="headerlink" title="4.2.4 Kafka安装"></a>4.2.4 Kafka安装</h3><h4 id="4-2-4-1-安装部署"><a href="#4-2-4-1-安装部署" class="headerlink" title="4.2.4.1 安装部署"></a>4.2.4.1 安装部署</h4><h5 id="4-2-4-1-1-集群规划"><a href="#4-2-4-1-1-集群规划" class="headerlink" title="4.2.4.1.1 集群规划"></a>4.2.4.1.1 集群规划</h5><table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>zk</td>
<td>zk</td>
<td>zk</td>
</tr>
<tr>
<td>kafka</td>
<td>kafka</td>
<td>kafka</td>
</tr>
</tbody></table>
<h5 id="4-2-4-1-2-集群部署"><a href="#4-2-4-1-2-集群部署" class="headerlink" title="4.2.4.1.2 集群部署"></a>4.2.4.1.2 集群部署</h5><p>0）官方下载地址：<a href="http://kafka.apache.org/downloads.html" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html</a></p>
<p>1）上传并解压安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf kafka_2.12-3.3.1.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>2）修改解压后的文件名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ cd /opt/module/</span><br><span class="line">[atguigu@hadoop102 module]$ mv kafka_2.12-3.3.1/ kafka</span><br></pre></td></tr></table></figure>

<p>3）进入到/opt/module/kafka目录，修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ cd config/</span><br><span class="line">[atguigu@hadoop102 config]$ vim server.properties</span><br></pre></td></tr></table></figure>

<p>输入以下内容：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复，只能是数字。</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）</span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://hadoop102:9092</span></span><br><span class="line"><span class="comment">#处理网络请求的线程数量</span></span><br><span class="line"><span class="meta">num.network.threads</span>=<span class="string">3</span></span><br><span class="line"><span class="comment">#用来处理磁盘IO的线程数量</span></span><br><span class="line"><span class="meta">num.io.threads</span>=<span class="string">8</span></span><br><span class="line"><span class="comment">#发送套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.send.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"><span class="comment">#接收套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.receive.buffer.bytes</span>=<span class="string">102400</span></span><br><span class="line"><span class="comment">#请求套接字的缓冲区大小</span></span><br><span class="line"><span class="meta">socket.request.max.bytes</span>=<span class="string">104857600</span></span><br><span class="line"><span class="comment">#kafka运行日志(数据)存放的路径，路径不需要提前创建，kafka自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用"，"分隔</span></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/opt/module/kafka/datas</span></span><br><span class="line"><span class="comment">#topic在当前broker上的分区个数</span></span><br><span class="line"><span class="meta">num.partitions</span>=<span class="string">1</span></span><br><span class="line"><span class="comment">#用来恢复和清理data下数据的线程数量</span></span><br><span class="line"><span class="meta">num.recovery.threads.per.data.dir</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># 每个topic创建时的副本数，默认时1个副本</span></span><br><span class="line"><span class="meta">offsets.topic.replication.factor</span>=<span class="string">1</span></span><br><span class="line"><span class="comment">#segment文件保留的最长时间，超时将被删除</span></span><br><span class="line"><span class="meta">log.retention.hours</span>=<span class="string">168</span></span><br><span class="line"><span class="comment">#每个segment文件的大小，默认最大1G</span></span><br><span class="line"><span class="meta">log.segment.bytes</span>=<span class="string">1073741824</span></span><br><span class="line"><span class="comment"># 检查过期数据的时间，默认5分钟检查一次是否数据过期</span></span><br><span class="line"><span class="meta">log.retention.check.interval.ms</span>=<span class="string">300000</span></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址（在zk根目录下创建/kafka，方便管理）</span></span><br><span class="line"><span class="meta">zookeeper.connect</span>=<span class="string">hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span></span><br></pre></td></tr></table></figure>

<p>4）分发安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ xsync kafka/</span><br></pre></td></tr></table></figure>

<p>5）分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id及advertised.listeners</p>
<p>​    注：broker.id不得重复，整个集群中唯一。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 module]$ vim kafka/config/server.properties</span><br><span class="line">修改:</span><br><span class="line"><span class="meta">#</span><span class="bash"> The id of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span> each broker.</span></span><br><span class="line">broker.id=1</span><br><span class="line"><span class="meta">#</span><span class="bash">broker对外暴露的IP和端口 （每个节点单独配置）</span></span><br><span class="line">advertised.listeners=PLAINTEXT://hadoop103:9092</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop104 module]$ vim kafka/config/server.properties</span><br><span class="line">修改:</span><br><span class="line"><span class="meta">#</span><span class="bash"> The id of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span> each broker.</span></span><br><span class="line">broker.id=2</span><br><span class="line"><span class="meta">#</span><span class="bash">broker对外暴露的IP和端口 （每个节点单独配置）</span></span><br><span class="line">advertised.listeners=PLAINTEXT://hadoop104:9092</span><br></pre></td></tr></table></figure>

<p>6）配置环境变量</p>
<p>（1）在/etc/profile.d/my_env.sh文件中增加kafka环境变量配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>增加如下内容：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#KAFKA_HOME</span></span><br><span class="line"><span class="attr">export</span> <span class="string">KAFKA_HOME=/opt/module/kafka</span></span><br><span class="line"><span class="attr">export</span> <span class="string">PATH=$PATH:$KAFKA_HOME/bin</span></span><br></pre></td></tr></table></figure>

<p>（2）刷新一下环境变量。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ source /etc/profile</span><br></pre></td></tr></table></figure>

<p>（3）分发环境变量文件到其他节点，并source。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ sudo /home/atguigu/bin/xsync /etc/profile.d/my_env.sh</span><br><span class="line">[atguigu@hadoop103 module]$ source /etc/profile</span><br><span class="line">[atguigu@hadoop104 module]$ source /etc/profile</span><br></pre></td></tr></table></figure>

<p>7）启动集群</p>
<p>（1）先启动Zookeeper集群，然后启动Kafka。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ zk.sh start</span><br></pre></td></tr></table></figure>

<p>（2）依次在hadoop102、hadoop103、hadoop104节点上启动Kafka。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">[atguigu@hadoop103 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">[atguigu@hadoop104 kafka]$ bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure>

<p>注意：配置文件的路径要能够到server.properties。</p>
<p>（3）查看进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ xcall jps</span><br></pre></td></tr></table></figure>

<p>如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--------- hadoop102 ----------</span><br><span class="line">3768 QuorumPeerMain</span><br><span class="line">4251 Kafka</span><br><span class="line">4349 Jps</span><br><span class="line">--------- hadoop103 ----------</span><br><span class="line">4769 Kafka</span><br><span class="line">4292 QuorumPeerMain</span><br><span class="line">4878 Jps</span><br><span class="line">--------- hadoop104 ----------</span><br><span class="line">3298 Jps</span><br><span class="line">3206 Kafka</span><br><span class="line">2719 QuorumPeerMain</span><br></pre></td></tr></table></figure>

<p>8）关闭集群</p>
<p>（1）依次在hadoop102、hadoop103、hadoop104节点上停止Kafka。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-server-stop.sh </span><br><span class="line">[atguigu@hadoop103 kafka]$ bin/kafka-server-stop.sh </span><br><span class="line">[atguigu@hadoop104 kafka]$ bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<p>（2）查看进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ xcall jps</span><br></pre></td></tr></table></figure>

<p>如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--------- hadoop102 ----------</span><br><span class="line">3768 QuorumPeerMain</span><br><span class="line">3868 Jps</span><br><span class="line">--------- hadoop103 ----------</span><br><span class="line">4292 QuorumPeerMain</span><br><span class="line">4390 Jps</span><br><span class="line">--------- hadoop104 ----------</span><br><span class="line">2810 Jps</span><br><span class="line">2719 QuorumPeerMain</span><br></pre></td></tr></table></figure>

<h5 id="4-2-4-1-3-集群启停脚本"><a href="#4-2-4-1-3-集群启停脚本" class="headerlink" title="4.2.4.1.3 集群启停脚本"></a>4.2.4.1.3 集群启停脚本</h5><p>1）在/home/atguigu/bin目录下创建文件kf.sh脚本文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ vim kf.sh</span><br></pre></td></tr></table></figure>

<p>脚本如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">! /bin/bash</span></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">"start")&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo " --------启动 $i Kafka-------"</span><br><span class="line">        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">"stop")&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo " --------停止 $i Kafka-------"</span><br><span class="line">        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh "</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>2）添加执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 kf.sh</span><br></pre></td></tr></table></figure>

<p>3）启动集群命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ kf.sh start</span><br></pre></td></tr></table></figure>

<p>4）停止集群命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ kf.sh stop</span><br></pre></td></tr></table></figure>

<p>注意：停止Kafka集群时，一定要等Kafka所有节点进程全部停止后再停止Zookeeper集群。因为Zookeeper集群当中记录着Kafka集群相关信息，Zookeeper集群一旦先停止，Kafka集群就没有办法再获取停止进程的信息，只能手动杀死Kafka进程了。</p>
<h4 id="4-2-4-2-Kafka命令行操作"><a href="#4-2-4-2-Kafka命令行操作" class="headerlink" title="4.2.4.2 Kafka命令行操作"></a>4.2.4.2 Kafka命令行操作</h4><h5 id="4-2-4-2-1-主题命令行操作"><a href="#4-2-4-2-1-主题命令行操作" class="headerlink" title="4.2.4.2.1 主题命令行操作"></a>4.2.4.2.1 主题命令行操作</h5><p>1）查看操作主题命令参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server toconnect to&gt;</td>
<td>连接的Kafka Broker主机名称和端口号。</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的topic名称。</td>
</tr>
<tr>
<td>–create</td>
<td>创建主题。</td>
</tr>
<tr>
<td>–delete</td>
<td>删除主题。</td>
</tr>
<tr>
<td>–alter</td>
<td>修改主题。</td>
</tr>
<tr>
<td>–list</td>
<td>查看所有主题。</td>
</tr>
<tr>
<td>–describe</td>
<td>查看主题详细描述。</td>
</tr>
<tr>
<td>–partitions &lt;Integer: # of partitions&gt;</td>
<td>设置分区数。</td>
</tr>
<tr>
<td>–replication-factor&lt;Integer: replication factor&gt;</td>
<td>设置分区副本。</td>
</tr>
<tr>
<td>–config &lt;String: name=value&gt;</td>
<td>更新系统默认的配置。</td>
</tr>
</tbody></table>
<p>2）查看当前服务器中的所有topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list</span><br></pre></td></tr></table></figure>

<p>3）创建first topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 1 --replication-factor 3 --topic first</span><br></pre></td></tr></table></figure>

<p>选项说明：</p>
<p>–topic 定义topic名</p>
<p>–replication-factor  定义副本数</p>
<p>–partitions  定义分区数</p>
<p>4）查看first主题的详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic first</span><br></pre></td></tr></table></figure>

<p>5）修改分区数（注意：分区数只能增加，不能减少）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 3</span><br></pre></td></tr></table></figure>

<p>6）再次查看first主题的详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic first</span><br></pre></td></tr></table></figure>

<p>7）删除topic（学生自己演示）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --delete --topic first</span><br></pre></td></tr></table></figure>

<h5 id="4-2-4-2-2-生产者命令行操作"><a href="#4-2-4-2-2-生产者命令行操作" class="headerlink" title="4.2.4.2.2 生产者命令行操作"></a>4.2.4.2.2 生产者命令行操作</h5><p>1）查看操作生产者命令参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-console-producer.sh</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server toconnect to&gt;</td>
<td>连接的Kafka Broker主机名称和端口号。</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的topic名称。</td>
</tr>
</tbody></table>
<p>2）发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">hello world</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">atguigu  atguigu</span></span><br></pre></td></tr></table></figure>

<h5 id="4-2-4-2-3-消费者命令行操作"><a href="#4-2-4-2-3-消费者命令行操作" class="headerlink" title="4.2.4.2.3 消费者命令行操作"></a>4.2.4.2.3 消费者命令行操作</h5><p>1）查看操作消费者命令参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server toconnect to&gt;</td>
<td>连接的Kafka Broker主机名称和端口号。</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的topic名称。</td>
</tr>
<tr>
<td>–from-beginning</td>
<td>从头开始消费。</td>
</tr>
<tr>
<td>–group &lt;String: consumer group id&gt;</td>
<td>指定消费者组名称。</td>
</tr>
</tbody></table>
<p>2）消费消息</p>
<p>（1）消费first主题中的数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first</span><br></pre></td></tr></table></figure>

<p>（2）把主题中所有的数据都读取出来（包括历史数据）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure>

<h3 id="4-2-5-Flume安装"><a href="#4-2-5-Flume安装" class="headerlink" title="4.2.5 Flume安装"></a>4.2.5 Flume安装</h3><p>按照采集通道规划，需在hadoop102，hadoop104两台节点分别部署一个Flume。可参照以下步骤先在hadoop102安装，然后再进行分发。</p>
<h4 id="4-2-5-1-安装步骤"><a href="#4-2-5-1-安装步骤" class="headerlink" title="4.2.5.1 安装步骤"></a>4.2.5.1 安装步骤</h4><h5 id="4-2-5-1-1-安装地址"><a href="#4-2-5-1-1-安装地址" class="headerlink" title="4.2.5.1.1 安装地址"></a>4.2.5.1.1 安装地址</h5><p>（1） Flume官网地址：<a href="http://flume.apache.org/" target="_blank" rel="noopener">http://flume.apache.org/</a></p>
<p>（2）文档查看地址：<a href="http://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html</a></p>
<p>（3）下载地址：<a href="http://archive.apache.org/dist/flume/" target="_blank" rel="noopener">http://archive.apache.org/dist/flume/</a></p>
<h5 id="4-2-5-1-2-安装部署"><a href="#4-2-5-1-2-安装部署" class="headerlink" title="4.2.5.1.2 安装部署"></a>4.2.5.1.2 安装部署</h5><p>（1）将apache-flume-1.10.1-bin.tar.gz上传到linux的/opt/software目录下</p>
<p>（2）解压apache-flume-1.10.1-bin.tar.gz到/opt/module/目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxf /opt/software/apache-flume-1.10.1-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>（3）修改apache-flume-1.10.1-bin的名称为flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ mv /opt/module/apache-flume-1.10.1-bin /opt/module/flume</span><br></pre></td></tr></table></figure>

<p>（4）修改conf目录下的log4j2.xml配置文件，配置日志文件路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 conf]$ vim log4j2.xml</span><br><span class="line"></span><br><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line"> Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="line"> contributor license agreements.  See the NOTICE file distributed with</span><br><span class="line"> this work for additional information regarding copyright ownership.</span><br><span class="line"> The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="line"> (the "License"); you may not use this file except in compliance with</span><br><span class="line"> the License.  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">      http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line"> Unless required by applicable law or agreed to in writing, software</span><br><span class="line"> distributed under the License is distributed on an "AS IS" BASIS,</span><br><span class="line"> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"> See the License for the specific language governing permissions and</span><br><span class="line"> limitations under the License.</span><br><span class="line"></span><br><span class="line"><span class="meta">--&gt;</span></span><br><span class="line">&lt;Configuration status="ERROR"&gt;</span><br><span class="line">  &lt;Properties&gt;</span><br><span class="line">    &lt;Property name="LOG_DIR"&gt;/opt/module/flume/log&lt;/Property&gt;</span><br><span class="line">  &lt;/Properties&gt;</span><br><span class="line">  &lt;Appenders&gt;</span><br><span class="line">    &lt;Console name="Console" target="SYSTEM_ERR"&gt;</span><br><span class="line">      &lt;PatternLayout pattern="%d (%t) [%p - %l] %m%n" /&gt;</span><br><span class="line">    &lt;/Console&gt;</span><br><span class="line">    &lt;RollingFile name="LogFile" fileName="$&#123;LOG_DIR&#125;/flume.log" filePattern="$&#123;LOG_DIR&#125;/archive/flume.log.%d&#123;yyyyMMdd&#125;-%i"&gt;</span><br><span class="line">      &lt;PatternLayout pattern="%d&#123;dd MMM yyyy HH:mm:ss,SSS&#125; %-5p [%t] (%C.%M:%L) %equals&#123;%x&#125;&#123;[]&#125;&#123;&#125; - %m%n" /&gt;</span><br><span class="line">      &lt;Policies&gt;</span><br><span class="line">        &lt;!-- Roll every night at midnight or when the file reaches 100MB --&gt;</span><br><span class="line">        &lt;SizeBasedTriggeringPolicy size="100 MB"/&gt;</span><br><span class="line">        &lt;CronTriggeringPolicy schedule="0 0 0 * * ?"/&gt;</span><br><span class="line">      &lt;/Policies&gt;</span><br><span class="line">      &lt;DefaultRolloverStrategy min="1" max="20"&gt;</span><br><span class="line">        &lt;Delete basePath="$&#123;LOG_DIR&#125;/archive"&gt;</span><br><span class="line">          &lt;!-- Nested conditions: the inner condition is only evaluated on files for which the outer conditions are true. --&gt;</span><br><span class="line">          &lt;IfFileName glob="flume.log."&gt;</span><br><span class="line">            &lt;!-- Only allow 1 GB of files to accumulate --&gt;</span><br><span class="line">            &lt;IfAccumulatedFileSize exceeds="1 GB"/&gt;</span><br><span class="line">          &lt;/IfFileName&gt;</span><br><span class="line">        &lt;/Delete&gt;</span><br><span class="line">      &lt;/DefaultRolloverStrategy&gt;</span><br><span class="line">    &lt;/RollingFile&gt;</span><br><span class="line">  &lt;/Appenders&gt;</span><br><span class="line"></span><br><span class="line">  &lt;Loggers&gt;</span><br><span class="line">    &lt;Logger name="org.apache.flume.lifecycle" level="info"/&gt;</span><br><span class="line">    &lt;Logger name="org.jboss" level="WARN"/&gt;</span><br><span class="line">    &lt;Logger name="org.apache.avro.ipc.netty.NettyTransceiver" level="WARN"/&gt;</span><br><span class="line">    &lt;Logger name="org.apache.hadoop" level="INFO"/&gt;</span><br><span class="line">&lt;Logger name="org.apache.hadoop.hive" level="ERROR"/&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 引入控制台输出，方便学习查看日志</span></span><br><span class="line">    &lt;Root level="INFO"&gt;</span><br><span class="line">      &lt;AppenderRef ref="LogFile" /&gt;</span><br><span class="line">      &lt;AppenderRef ref="Console" /&gt;</span><br><span class="line">    &lt;/Root&gt;</span><br><span class="line">  &lt;/Loggers&gt;</span><br><span class="line"></span><br><span class="line">&lt;/Configuration&gt;</span><br></pre></td></tr></table></figure>

<h4 id="4-2-5-2-分发Flume"><a href="#4-2-5-2-分发Flume" class="headerlink" title="4.2.5.2 分发Flume"></a>4.2.5.2 分发Flume</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ xsync /opt/module/flume/</span><br></pre></td></tr></table></figure>

<h4 id="4-2-5-3-项目经验"><a href="#4-2-5-3-项目经验" class="headerlink" title="4.2.5.3 项目经验"></a>4.2.5.3 项目经验</h4><p>（1）堆内存调整</p>
<p>Flume堆内存通常设置为4G或更高，配置方式如下：</p>
<p>修改/opt/module/flume/conf/flume-env.sh文件，配置如下参数（虚拟机环境暂不配置）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_OPTS="-Xms4096m -Xmx4096m -Dcom.sun.management.jmxremote"</span><br></pre></td></tr></table></figure>

<p>注：</p>
<p>-Xms表示JVM Heap（堆内存）最小尺寸，初始分配。</p>
<p>-Xmx 表示JVM Heap（堆内存）最大允许的尺寸，按需分配。</p>
<h2 id="4-3-日志采集Flume"><a href="#4-3-日志采集Flume" class="headerlink" title="4.3 日志采集Flume"></a>4.3 日志采集Flume</h2><h3 id="4-3-1-日志采集Flume配置概述"><a href="#4-3-1-日志采集Flume配置概述" class="headerlink" title="4.3.1 日志采集Flume配置概述"></a>4.3.1 日志采集Flume配置概述</h3><p>按照规划，需要采集的用户行为日志文件存放在hadoop102，故需要在该节点配置日志采集Flume。日志采集Flume需要采集日志文件内容，并对日志格式（JSON）进行校验，然后将校验通过的日志发送到Kafka。</p>
<p>此处可选择 TaildirSource 和 KafkaChannel ，并配置日志校验拦截器。</p>
<p>选择TailDirSource和KafkaChannel的原因如下：</p>
<p>1）TailDirSource</p>
<p>TailDirSource相比ExecSource、SpoolingDirectorySource的优势。</p>
<p>TailDirSource：断点续传、多目录。Flume1.6以前需要自己自定义Source记录每次读取文件位置，实现断点续传。</p>
<p>ExecSource可以实时搜集数据，但是在Flume不运行或者Shell命令出错的情况下，数据将会丢失。</p>
<p>SpoolingDirectorySource监控目录，支持断点续传。</p>
<p>2）KafkaChannel</p>
<p>采用Kafka Channel，省去了Sink，提高了效率。</p>
<p>日志采集Flume关键配置如下：</p>
<p><img src="/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/wps9-1723102801713-1.png" alt="img"></p>
<h3 id="4-3-2-日志采集Flume配置实操"><a href="#4-3-2-日志采集Flume配置实操" class="headerlink" title="4.3.2 日志采集Flume配置实操"></a>4.3.2 日志采集Flume配置实操</h3><p>1）创建Flume配置文件</p>
<p>在hadoop102节点的Flume的job目录下创建file_to_kafka.conf。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 flume]$ mkdir job</span><br><span class="line">[atguigu@hadoop102 flume]$ vim job/file_to_kafka.conf</span><br></pre></td></tr></table></figure>

<p>2）配置文件内容如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">定义组件</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">配置<span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.filegroups = f1</span><br><span class="line">a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*</span><br><span class="line">a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">配置channel</span></span><br><span class="line">a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel</span><br><span class="line">a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092</span><br><span class="line">a1.channels.c1.kafka.topic = topic_log</span><br><span class="line">a1.channels.c1.parseAsFlumeEvent = false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">组装 </span></span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure>

<h3 id="4-3-3-日志采集Flume测试"><a href="#4-3-3-日志采集Flume测试" class="headerlink" title="4.3.3 日志采集Flume测试"></a>4.3.3 日志采集Flume测试</h3><p>1）启动Zookeeper、Kafka集群</p>
<p>2）启动hadoop102的日志采集Flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 flume]$ bin/flume-ng agent -n a1 -c conf/ -f job/file_to_kafka.conf</span><br></pre></td></tr></table></figure>

<p>3）启动一个Kafka的Console-Consumer</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic topic_log</span><br></pre></td></tr></table></figure>

<p>4）生成数据</p>
<p>执行集群日志生成脚本。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ lg.sh test 100</span><br></pre></td></tr></table></figure>

<p>5）观察Kafka消费者是否能消费到数据</p>
<h3 id="4-3-4-日志采集Flume启停脚本"><a href="#4-3-4-日志采集Flume启停脚本" class="headerlink" title="4.3.4 日志采集Flume启停脚本"></a>4.3.4 日志采集Flume启停脚本</h3><p>1）在hadoop102节点的/home/atguigu/bin目录下创建脚本f1.sh</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ vim f1.sh</span><br></pre></td></tr></table></figure>

<p>在脚本中填写如下内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">"start")&#123;</span><br><span class="line">    echo " --------启动 hadoop102 采集flume-------"</span><br><span class="line">    ssh hadoop102 "nohup /opt/module/flume/bin/flume-ng agent -n a1 -c /opt/module/flume/conf/ -f /opt/module/flume/job/file_to_kafka.conf &gt;/dev/null 2&gt;&amp;1 &amp;"</span><br><span class="line">&#125;;; </span><br><span class="line">"stop")&#123;</span><br><span class="line">    echo " --------停止 hadoop102 采集flume-------"</span><br><span class="line">    ssh hadoop102 "ps -ef | grep file_to_kafka | grep -v grep |awk  '&#123;print \$2&#125;' | xargs -n1 kill -9 "</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>2）增加脚本执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 f1.sh</span><br></pre></td></tr></table></figure>

<p>3）f1启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ f1.sh start</span><br></pre></td></tr></table></figure>

<p>4）f1停止</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ f1.sh stop</span><br></pre></td></tr></table></figure>


    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Rui Zhang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2024/07/31/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B01/" title="电商数仓项目-用户行为采集平台1">http://yoursite.com/2024/07/31/电商数仓项目-用户行为采集平台1/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%95%B0%E4%BB%93/" rel="tag"># 数仓</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/07/30/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E5%89%8D%E7%BD%AE%E6%A6%82%E5%BF%B50/" rel="prev" title="电商数仓项目-前置概念0">
      <i class="fa fa-chevron-left"></i> 电商数仓项目-前置概念0
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/08/08/%E7%94%B5%E5%95%86%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE-%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B9%B3%E5%8F%B02/" rel="next" title="电商数仓项目-业务数据采集平台2">
      电商数仓项目-业务数据采集平台2 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#第1章-数据仓库概念"><span class="nav-number">1.</span> <span class="nav-text">第1章 数据仓库概念</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第2章-项目需求及架构设计"><span class="nav-number">2.</span> <span class="nav-text">第2章 项目需求及架构设计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-项目需求分析"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 项目需求分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-项目框架"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 项目框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-技术选型"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1 技术选型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-系统数据流程设计"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2 系统数据流程设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-3-框架版本选型"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.2.3 框架版本选型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-4-服务器选型"><span class="nav-number">2.2.4.</span> <span class="nav-text">2.2.4 服务器选型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-5-集群规模"><span class="nav-number">2.2.5.</span> <span class="nav-text">2.2.5 集群规模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-6-集群资源规划设计"><span class="nav-number">2.2.6.</span> <span class="nav-text">2.2.6 集群资源规划设计</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第3章-用户行为日志"><span class="nav-number">3.</span> <span class="nav-text">第3章 用户行为日志</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-用户行为日志概述"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 用户行为日志概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-用户行为日志内容"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 用户行为日志内容</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-页面浏览记录"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1 页面浏览记录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-动作记录"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2 动作记录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-曝光记录"><span class="nav-number">3.2.3.</span> <span class="nav-text">3.2.3 曝光记录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-4-启动记录"><span class="nav-number">3.2.4.</span> <span class="nav-text">3.2.4 启动记录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-5-错误记录"><span class="nav-number">3.2.5.</span> <span class="nav-text">3.2.5 错误记录</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-用户行为日志格式"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 用户行为日志格式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-1-页面日志"><span class="nav-number">3.3.1.</span> <span class="nav-text">3.3.1 页面日志</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-2-启动日志"><span class="nav-number">3.3.2.</span> <span class="nav-text">3.3.2 启动日志</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-服务器和JDK准备"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 服务器和JDK准备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-1-服务器准备"><span class="nav-number">3.4.1.</span> <span class="nav-text">3.4.1 服务器准备</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-1-1-模板虚拟机环境准备"><span class="nav-number">3.4.1.1.</span> <span class="nav-text">3.4.1.1 模板虚拟机环境准备</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-1-2-克隆虚拟机"><span class="nav-number">3.4.1.2.</span> <span class="nav-text">3.4.1.2 克隆虚拟机</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-2-阿里云服务器准备（可选）"><span class="nav-number">3.4.2.</span> <span class="nav-text">3.4.2 阿里云服务器准备（可选）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-2-1-注册阿里云账户"><span class="nav-number">3.4.2.1.</span> <span class="nav-text">3.4.2.1 注册阿里云账户</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-2-2-购买ECS云服务器"><span class="nav-number">3.4.2.2.</span> <span class="nav-text">3.4.2.2 购买ECS云服务器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-2-3-ECS配置及安全组修改"><span class="nav-number">3.4.2.3.</span> <span class="nav-text">3.4.2.3 ECS配置及安全组修改</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-2-4-连接阿里云服务器"><span class="nav-number">3.4.2.4.</span> <span class="nav-text">3.4.2.4 连接阿里云服务器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-2-5-修改服务器hosts文件"><span class="nav-number">3.4.2.5.</span> <span class="nav-text">3.4.2.5 修改服务器hosts文件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-3-编写集群分发脚本xsync"><span class="nav-number">3.4.3.</span> <span class="nav-text">3.4.3 编写集群分发脚本xsync</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-4-SSH无密登录配置"><span class="nav-number">3.4.4.</span> <span class="nav-text">3.4.4 SSH无密登录配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-5-JDK准备"><span class="nav-number">3.4.5.</span> <span class="nav-text">3.4.5 JDK准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-6-环境变量配置说明"><span class="nav-number">3.4.6.</span> <span class="nav-text">3.4.6 环境变量配置说明</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-5-数据模拟"><span class="nav-number">3.5.</span> <span class="nav-text">3.5 数据模拟</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-1-使用说明"><span class="nav-number">3.5.1.</span> <span class="nav-text">3.5.1 使用说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-2-集群日志生成脚本"><span class="nav-number">3.5.2.</span> <span class="nav-text">3.5.2 集群日志生成脚本</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第4章-用户行为数据采集模块"><span class="nav-number">4.</span> <span class="nav-text">第4章 用户行为数据采集模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-数据通道"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 数据通道</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-环境准备"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 环境准备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-集群命令批量执行脚本"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1 集群命令批量执行脚本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-Hadoop安装"><span class="nav-number">4.2.2.</span> <span class="nav-text">4.2.2 Hadoop安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-2-1-安装步骤"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">4.2.2.1 安装步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-1-Hadoop部署"><span class="nav-number">4.2.2.1.1.</span> <span class="nav-text">4.2.2.1.1 Hadoop部署</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-2-配置集群"><span class="nav-number">4.2.2.1.2.</span> <span class="nav-text">4.2.2.1.2 配置集群</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-3-配置历史服务器"><span class="nav-number">4.2.2.1.3.</span> <span class="nav-text">4.2.2.1.3 配置历史服务器</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-4-配置日志的聚集"><span class="nav-number">4.2.2.1.4.</span> <span class="nav-text">4.2.2.1.4 配置日志的聚集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-5-分发Hadoop"><span class="nav-number">4.2.2.1.5.</span> <span class="nav-text">4.2.2.1.5 分发Hadoop</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-6-群起集群"><span class="nav-number">4.2.2.1.6.</span> <span class="nav-text">4.2.2.1.6 群起集群</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-2-1-7-Hadoop群起脚本"><span class="nav-number">4.2.2.1.7.</span> <span class="nav-text">4.2.2.1.7 Hadoop群起脚本</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-2-2-项目经验"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">4.2.2.2 项目经验</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-Zookeeper安装"><span class="nav-number">4.2.3.</span> <span class="nav-text">4.2.3 Zookeeper安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-1-分布式安装部署"><span class="nav-number">4.2.3.1.</span> <span class="nav-text">4.2.3.1 分布式安装部署</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-2-ZK集群启动停止脚本"><span class="nav-number">4.2.3.2.</span> <span class="nav-text">4.2.3.2 ZK集群启动停止脚本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-3-客户端命令行操作"><span class="nav-number">4.2.3.3.</span> <span class="nav-text">4.2.3.3 客户端命令行操作</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-4-Kafka安装"><span class="nav-number">4.2.4.</span> <span class="nav-text">4.2.4 Kafka安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-4-1-安装部署"><span class="nav-number">4.2.4.1.</span> <span class="nav-text">4.2.4.1 安装部署</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-4-1-1-集群规划"><span class="nav-number">4.2.4.1.1.</span> <span class="nav-text">4.2.4.1.1 集群规划</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-4-1-2-集群部署"><span class="nav-number">4.2.4.1.2.</span> <span class="nav-text">4.2.4.1.2 集群部署</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-4-1-3-集群启停脚本"><span class="nav-number">4.2.4.1.3.</span> <span class="nav-text">4.2.4.1.3 集群启停脚本</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-4-2-Kafka命令行操作"><span class="nav-number">4.2.4.2.</span> <span class="nav-text">4.2.4.2 Kafka命令行操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-4-2-1-主题命令行操作"><span class="nav-number">4.2.4.2.1.</span> <span class="nav-text">4.2.4.2.1 主题命令行操作</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-4-2-2-生产者命令行操作"><span class="nav-number">4.2.4.2.2.</span> <span class="nav-text">4.2.4.2.2 生产者命令行操作</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-4-2-3-消费者命令行操作"><span class="nav-number">4.2.4.2.3.</span> <span class="nav-text">4.2.4.2.3 消费者命令行操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-5-Flume安装"><span class="nav-number">4.2.5.</span> <span class="nav-text">4.2.5 Flume安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-5-1-安装步骤"><span class="nav-number">4.2.5.1.</span> <span class="nav-text">4.2.5.1 安装步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-5-1-1-安装地址"><span class="nav-number">4.2.5.1.1.</span> <span class="nav-text">4.2.5.1.1 安装地址</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-5-1-2-安装部署"><span class="nav-number">4.2.5.1.2.</span> <span class="nav-text">4.2.5.1.2 安装部署</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-5-2-分发Flume"><span class="nav-number">4.2.5.2.</span> <span class="nav-text">4.2.5.2 分发Flume</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-5-3-项目经验"><span class="nav-number">4.2.5.3.</span> <span class="nav-text">4.2.5.3 项目经验</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-日志采集Flume"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 日志采集Flume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-1-日志采集Flume配置概述"><span class="nav-number">4.3.1.</span> <span class="nav-text">4.3.1 日志采集Flume配置概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-日志采集Flume配置实操"><span class="nav-number">4.3.2.</span> <span class="nav-text">4.3.2 日志采集Flume配置实操</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-3-日志采集Flume测试"><span class="nav-number">4.3.3.</span> <span class="nav-text">4.3.3 日志采集Flume测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-4-日志采集Flume启停脚本"><span class="nav-number">4.3.4.</span> <span class="nav-text">4.3.4 日志采集Flume启停脚本</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Rui Zhang"
      src="/images/head.jpg">
  <p class="site-author-name" itemprop="name">Rui Zhang</p>
  <div class="site-description" itemprop="description">不在沉默中爆发，就在沉默中灭亡</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2021 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Rui Zhang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">1.7m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">25:10</span>
</div>




        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":120,"height":230},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
